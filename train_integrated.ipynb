{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145ff5f8-a464-42c0-b226-8e658ce4689a",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fb08b0-359f-41ab-901f-da3a77725381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from LibAUC.libauc.losses import MultiLabelAUCMLoss,CrossEntropyLoss\n",
    "from LibAUC.libauc.optimizers import PESG,Adam\n",
    "from LibAUC.libauc.models import densenet121 as DenseNet121\n",
    "from LibAUC.libauc.models import resnet34 as Resnet34\n",
    "from LibAUC.libauc.models import resnet50 as Resnet50\n",
    "from LibAUC.libauc.datasets import CheXpert\n",
    "from LibAUC.libauc.metrics import auc_roc_score # for multi-task\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eebc0ec-eb09-42f6-8af0-23dcf95bf5df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_all_seeds(SEED):\n",
    "    # REPRODUCIBILITY\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning) # Delete Future Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76d45dd-5b8a-4a99-9a19-e502bd97dc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "lr = 0.1\n",
    "epoch_decay = 2e-3\n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "total_epochs = 6\n",
    "os.makedirs(os.path.join(os.getcwd(),'pth_files'),exist_ok=True)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174acb6-1d0a-4072-8fda-6fbf9aeecd13",
   "metadata": {},
   "source": [
    "# Densenet121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea6ffb-3faa-401d-90f9-333bc1768c18",
   "metadata": {},
   "source": [
    "## Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b435a2-e8bc-4f7f-baf1-9e992a6f1858",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 133781 images in total, 16297 positive images, 117484 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1218\n",
      "\n",
      "Found 133781 images in total, 42794 positive images, 90987 negative images\n",
      "Edema(C1): imbalance ratio is 0.3199\n",
      "\n",
      "Found 133781 images in total, 9055 positive images, 124726 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0677\n",
      "\n",
      "Found 133781 images in total, 41919 positive images, 91862 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3133\n",
      "\n",
      "Found 133781 images in total, 53675 positive images, 80106 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4012\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19090 images in total, 2242 positive images, 16848 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1174\n",
      "\n",
      "Found 19090 images in total, 6161 positive images, 12929 negative images\n",
      "Edema(C1): imbalance ratio is 0.3227\n",
      "\n",
      "Found 19090 images in total, 1346 positive images, 17744 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0705\n",
      "\n",
      "Found 19090 images in total, 5843 positive images, 13247 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3061\n",
      "\n",
      "Found 19090 images in total, 7762 positive images, 11328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4066\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:45)Epoch=0,BatchID=0,Val_AUC=0.4853,Best_Val_AUC=0.4853\n",
      "(00:05:02)Epoch=0,BatchID=400,Val_AUC=0.7061,Best_Val_AUC=0.7061\n",
      "(00:08:22)Epoch=0,BatchID=800,Val_AUC=0.7419,Best_Val_AUC=0.7419\n",
      "(00:12:09)Epoch=0,BatchID=1200,Val_AUC=0.7571,Best_Val_AUC=0.7571\n",
      "(00:15:36)Epoch=0,BatchID=1600,Val_AUC=0.7523,Best_Val_AUC=0.7571\n",
      "(00:18:57)Epoch=0,BatchID=2000,Val_AUC=0.7651,Best_Val_AUC=0.7651\n",
      "(00:22:18)Epoch=0,BatchID=2400,Val_AUC=0.7632,Best_Val_AUC=0.7651\n",
      "(00:25:39)Epoch=0,BatchID=2800,Val_AUC=0.7698,Best_Val_AUC=0.7698\n",
      "(00:29:00)Epoch=0,BatchID=3200,Val_AUC=0.7339,Best_Val_AUC=0.7698\n",
      "(00:32:20)Epoch=0,BatchID=3600,Val_AUC=0.7766,Best_Val_AUC=0.7766\n",
      "(00:35:41)Epoch=0,BatchID=4000,Val_AUC=0.7773,Best_Val_AUC=0.7773\n",
      "(00:37:53)Epoch=0,BatchID=4180,Val_AUC=0.7560,Best_Val_AUC=0.7773\n",
      "Reducing learning rate to 0.01000 @ T=4181!\n",
      "Updating regularizer @ T=4181!\n",
      "(00:39:38)Epoch=1,BatchID=0,Val_AUC=0.7567,Best_Val_AUC=0.7773\n",
      "(00:42:58)Epoch=1,BatchID=400,Val_AUC=0.7888,Best_Val_AUC=0.7888\n",
      "(00:46:18)Epoch=1,BatchID=800,Val_AUC=0.7902,Best_Val_AUC=0.7902\n",
      "(00:49:39)Epoch=1,BatchID=1200,Val_AUC=0.7918,Best_Val_AUC=0.7918\n",
      "(00:53:00)Epoch=1,BatchID=1600,Val_AUC=0.7923,Best_Val_AUC=0.7923\n",
      "(00:56:21)Epoch=1,BatchID=2000,Val_AUC=0.7932,Best_Val_AUC=0.7932\n",
      "(00:59:42)Epoch=1,BatchID=2400,Val_AUC=0.7945,Best_Val_AUC=0.7945\n",
      "(01:03:06)Epoch=1,BatchID=2800,Val_AUC=0.7920,Best_Val_AUC=0.7945\n",
      "(01:06:27)Epoch=1,BatchID=3200,Val_AUC=0.7951,Best_Val_AUC=0.7951\n",
      "(01:09:47)Epoch=1,BatchID=3600,Val_AUC=0.7942,Best_Val_AUC=0.7951\n",
      "(01:13:07)Epoch=1,BatchID=4000,Val_AUC=0.7954,Best_Val_AUC=0.7954\n",
      "(01:15:19)Epoch=1,BatchID=4180,Val_AUC=0.7944,Best_Val_AUC=0.7954\n",
      "Reducing learning rate to 0.00100 @ T=8362!\n",
      "Updating regularizer @ T=8362!\n",
      "(01:17:06)Epoch=2,BatchID=0,Val_AUC=0.7945,Best_Val_AUC=0.7954\n",
      "(01:20:28)Epoch=2,BatchID=400,Val_AUC=0.7964,Best_Val_AUC=0.7964\n",
      "(01:23:49)Epoch=2,BatchID=800,Val_AUC=0.7965,Best_Val_AUC=0.7965\n",
      "(01:27:10)Epoch=2,BatchID=1200,Val_AUC=0.7964,Best_Val_AUC=0.7965\n",
      "(01:30:31)Epoch=2,BatchID=1600,Val_AUC=0.7967,Best_Val_AUC=0.7967\n",
      "(01:33:51)Epoch=2,BatchID=2000,Val_AUC=0.7963,Best_Val_AUC=0.7967\n",
      "(01:37:12)Epoch=2,BatchID=2400,Val_AUC=0.7967,Best_Val_AUC=0.7967\n",
      "(01:40:34)Epoch=2,BatchID=2800,Val_AUC=0.7967,Best_Val_AUC=0.7967\n",
      "(01:43:55)Epoch=2,BatchID=3200,Val_AUC=0.7968,Best_Val_AUC=0.7968\n",
      "(01:47:16)Epoch=2,BatchID=3600,Val_AUC=0.7967,Best_Val_AUC=0.7968\n",
      "(01:50:38)Epoch=2,BatchID=4000,Val_AUC=0.7968,Best_Val_AUC=0.7968\n",
      "(01:52:51)Epoch=2,BatchID=4180,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "Reducing learning rate to 0.00010 @ T=12543!\n",
      "Updating regularizer @ T=12543!\n",
      "(01:54:38)Epoch=3,BatchID=0,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "(01:57:59)Epoch=3,BatchID=400,Val_AUC=0.7968,Best_Val_AUC=0.7969\n",
      "(02:01:19)Epoch=3,BatchID=800,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "(02:04:40)Epoch=3,BatchID=1200,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "(02:08:02)Epoch=3,BatchID=1600,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "(02:11:23)Epoch=3,BatchID=2000,Val_AUC=0.7969,Best_Val_AUC=0.7969\n",
      "(02:14:45)Epoch=3,BatchID=2400,Val_AUC=0.7970,Best_Val_AUC=0.7970\n",
      "(02:18:06)Epoch=3,BatchID=2800,Val_AUC=0.7969,Best_Val_AUC=0.7970\n",
      "(02:21:27)Epoch=3,BatchID=3200,Val_AUC=0.7969,Best_Val_AUC=0.7970\n",
      "(02:24:48)Epoch=3,BatchID=3600,Val_AUC=0.7969,Best_Val_AUC=0.7970\n",
      "(02:28:09)Epoch=3,BatchID=4000,Val_AUC=0.7971,Best_Val_AUC=0.7971\n",
      "(02:30:22)Epoch=3,BatchID=4180,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "Reducing learning rate to 0.00001 @ T=16724!\n",
      "Updating regularizer @ T=16724!\n",
      "(02:32:09)Epoch=4,BatchID=0,Val_AUC=0.7971,Best_Val_AUC=0.7971\n",
      "(02:35:30)Epoch=4,BatchID=400,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(02:38:52)Epoch=4,BatchID=800,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(02:42:13)Epoch=4,BatchID=1200,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(02:45:33)Epoch=4,BatchID=1600,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(02:48:55)Epoch=4,BatchID=2000,Val_AUC=0.7971,Best_Val_AUC=0.7971\n",
      "(02:52:16)Epoch=4,BatchID=2400,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(02:55:38)Epoch=4,BatchID=2800,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(02:58:59)Epoch=4,BatchID=3200,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(03:02:20)Epoch=4,BatchID=3600,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(03:05:42)Epoch=4,BatchID=4000,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(03:07:55)Epoch=4,BatchID=4180,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "Reducing learning rate to 0.00000 @ T=20905!\n",
      "Updating regularizer @ T=20905!\n",
      "(03:09:42)Epoch=5,BatchID=0,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:13:03)Epoch=5,BatchID=400,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:16:24)Epoch=5,BatchID=800,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:19:45)Epoch=5,BatchID=1200,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:23:06)Epoch=5,BatchID=1600,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:26:27)Epoch=5,BatchID=2000,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:29:49)Epoch=5,BatchID=2400,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:33:10)Epoch=5,BatchID=2800,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:36:30)Epoch=5,BatchID=3200,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(03:39:51)Epoch=5,BatchID=3600,Val_AUC=0.7969,Best_Val_AUC=0.7971\n",
      "(03:43:13)Epoch=5,BatchID=4000,Val_AUC=0.7970,Best_Val_AUC=0.7971\n",
      "(03:45:26)Epoch=5,BatchID=4180,Val_AUC=0.7970,Best_Val_AUC=0.7971\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_origin\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True,last_activation=None,activations='relu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "                \n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model_densenet121.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2c769-e40f-46b0-87b7-f688cfd29c41",
   "metadata": {},
   "source": [
    "## Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcecb46-81de-4273-8417-a53fcb254383",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 78644 images in total, 9943 positive images, 68701 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1264\n",
      "\n",
      "Found 78644 images in total, 24591 positive images, 54053 negative images\n",
      "Edema(C1): imbalance ratio is 0.3127\n",
      "\n",
      "Found 78644 images in total, 5314 positive images, 73330 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0676\n",
      "\n",
      "Found 78644 images in total, 24764 positive images, 53880 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3149\n",
      "\n",
      "Found 78644 images in total, 31305 positive images, 47339 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3981\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 11159 images in total, 1392 positive images, 9767 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1247\n",
      "\n",
      "Found 11159 images in total, 3541 positive images, 7618 negative images\n",
      "Edema(C1): imbalance ratio is 0.3173\n",
      "\n",
      "Found 11159 images in total, 762 positive images, 10397 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 11159 images in total, 3527 positive images, 7632 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3161\n",
      "\n",
      "Found 11159 images in total, 4573 positive images, 6586 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4098\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:28)Epoch=0,BatchID=0,Val_AUC=0.4816,Best_Val_AUC=0.4816\n",
      "(00:04:30)Epoch=0,BatchID=400,Val_AUC=0.7024,Best_Val_AUC=0.7024\n",
      "(00:07:32)Epoch=0,BatchID=800,Val_AUC=0.7382,Best_Val_AUC=0.7382\n",
      "(00:10:33)Epoch=0,BatchID=1200,Val_AUC=0.7600,Best_Val_AUC=0.7600\n",
      "(00:13:34)Epoch=0,BatchID=1600,Val_AUC=0.7607,Best_Val_AUC=0.7607\n",
      "(00:16:36)Epoch=0,BatchID=2000,Val_AUC=0.7722,Best_Val_AUC=0.7722\n",
      "(00:19:38)Epoch=0,BatchID=2400,Val_AUC=0.7668,Best_Val_AUC=0.7722\n",
      "(00:20:53)Epoch=0,BatchID=2457,Val_AUC=0.7711,Best_Val_AUC=0.7722\n",
      "Reducing learning rate to 0.01000 @ T=2458!\n",
      "Updating regularizer @ T=2458!\n",
      "(00:22:19)Epoch=1,BatchID=0,Val_AUC=0.7711,Best_Val_AUC=0.7722\n",
      "(00:25:20)Epoch=1,BatchID=400,Val_AUC=0.7837,Best_Val_AUC=0.7837\n",
      "(00:28:22)Epoch=1,BatchID=800,Val_AUC=0.7857,Best_Val_AUC=0.7857\n",
      "(00:31:23)Epoch=1,BatchID=1200,Val_AUC=0.7864,Best_Val_AUC=0.7864\n",
      "(00:34:24)Epoch=1,BatchID=1600,Val_AUC=0.7871,Best_Val_AUC=0.7871\n",
      "(00:37:25)Epoch=1,BatchID=2000,Val_AUC=0.7884,Best_Val_AUC=0.7884\n",
      "(00:40:26)Epoch=1,BatchID=2400,Val_AUC=0.7892,Best_Val_AUC=0.7892\n",
      "(00:41:40)Epoch=1,BatchID=2457,Val_AUC=0.7887,Best_Val_AUC=0.7892\n",
      "Reducing learning rate to 0.00100 @ T=4916!\n",
      "Updating regularizer @ T=4916!\n",
      "(00:43:07)Epoch=2,BatchID=0,Val_AUC=0.7887,Best_Val_AUC=0.7892\n",
      "(00:46:08)Epoch=2,BatchID=400,Val_AUC=0.7892,Best_Val_AUC=0.7892\n",
      "(00:49:09)Epoch=2,BatchID=800,Val_AUC=0.7895,Best_Val_AUC=0.7895\n",
      "(00:52:09)Epoch=2,BatchID=1200,Val_AUC=0.7894,Best_Val_AUC=0.7895\n",
      "(00:55:11)Epoch=2,BatchID=1600,Val_AUC=0.7895,Best_Val_AUC=0.7895\n",
      "(00:58:11)Epoch=2,BatchID=2000,Val_AUC=0.7896,Best_Val_AUC=0.7896\n",
      "(01:01:12)Epoch=2,BatchID=2400,Val_AUC=0.7898,Best_Val_AUC=0.7898\n",
      "(01:02:27)Epoch=2,BatchID=2457,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "Reducing learning rate to 0.00010 @ T=7374!\n",
      "Updating regularizer @ T=7374!\n",
      "(01:03:53)Epoch=3,BatchID=0,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:06:54)Epoch=3,BatchID=400,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:09:54)Epoch=3,BatchID=800,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:12:56)Epoch=3,BatchID=1200,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:15:56)Epoch=3,BatchID=1600,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:18:57)Epoch=3,BatchID=2000,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:21:58)Epoch=3,BatchID=2400,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:23:13)Epoch=3,BatchID=2457,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "Reducing learning rate to 0.00001 @ T=9832!\n",
      "Updating regularizer @ T=9832!\n",
      "(01:24:39)Epoch=4,BatchID=0,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:27:40)Epoch=4,BatchID=400,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:30:41)Epoch=4,BatchID=800,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:33:41)Epoch=4,BatchID=1200,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:36:41)Epoch=4,BatchID=1600,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:39:43)Epoch=4,BatchID=2000,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:42:44)Epoch=4,BatchID=2400,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:43:58)Epoch=4,BatchID=2457,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "Reducing learning rate to 0.00000 @ T=12290!\n",
      "Updating regularizer @ T=12290!\n",
      "(01:45:25)Epoch=5,BatchID=0,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(01:48:26)Epoch=5,BatchID=400,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:51:26)Epoch=5,BatchID=800,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:54:28)Epoch=5,BatchID=1200,Val_AUC=0.7899,Best_Val_AUC=0.7899\n",
      "(01:57:28)Epoch=5,BatchID=1600,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(02:00:29)Epoch=5,BatchID=2000,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(02:03:30)Epoch=5,BatchID=2400,Val_AUC=0.7898,Best_Val_AUC=0.7899\n",
      "(02:04:44)Epoch=5,BatchID=2457,Val_AUC=0.7898,Best_Val_AUC=0.7899\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_male\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True,last_activation=None,activations='relu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model_densenet121.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7db241-af42-44f8-9785-c223b3792ea8",
   "metadata": {},
   "source": [
    "## Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46191339-176a-4915-a60d-cd8b07f7f49d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 55137 images in total, 6354 positive images, 48783 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1152\n",
      "\n",
      "Found 55137 images in total, 18203 positive images, 36934 negative images\n",
      "Edema(C1): imbalance ratio is 0.3301\n",
      "\n",
      "Found 55137 images in total, 3741 positive images, 51396 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0678\n",
      "\n",
      "Found 55137 images in total, 17155 positive images, 37982 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3111\n",
      "\n",
      "Found 55137 images in total, 22370 positive images, 32767 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4057\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 7931 images in total, 850 positive images, 7081 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1072\n",
      "\n",
      "Found 7931 images in total, 2620 positive images, 5311 negative images\n",
      "Edema(C1): imbalance ratio is 0.3303\n",
      "\n",
      "Found 7931 images in total, 584 positive images, 7347 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0736\n",
      "\n",
      "Found 7931 images in total, 2316 positive images, 5615 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2920\n",
      "\n",
      "Found 7931 images in total, 3189 positive images, 4742 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4021\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:20)Epoch=0,BatchID=0,Val_AUC=0.4840,Best_Val_AUC=0.4840\n",
      "(00:04:13)Epoch=0,BatchID=400,Val_AUC=0.7018,Best_Val_AUC=0.7018\n",
      "(00:07:07)Epoch=0,BatchID=800,Val_AUC=0.7477,Best_Val_AUC=0.7477\n",
      "(00:10:00)Epoch=0,BatchID=1200,Val_AUC=0.7612,Best_Val_AUC=0.7612\n",
      "(00:12:52)Epoch=0,BatchID=1600,Val_AUC=0.7649,Best_Val_AUC=0.7649\n",
      "(00:14:18)Epoch=0,BatchID=1723,Val_AUC=0.7715,Best_Val_AUC=0.7715\n",
      "Reducing learning rate to 0.01000 @ T=1724!\n",
      "Updating regularizer @ T=1724!\n",
      "(00:15:35)Epoch=1,BatchID=0,Val_AUC=0.7714,Best_Val_AUC=0.7715\n",
      "(00:18:27)Epoch=1,BatchID=400,Val_AUC=0.7815,Best_Val_AUC=0.7815\n",
      "(00:21:19)Epoch=1,BatchID=800,Val_AUC=0.7816,Best_Val_AUC=0.7816\n",
      "(00:24:12)Epoch=1,BatchID=1200,Val_AUC=0.7820,Best_Val_AUC=0.7820\n",
      "(00:27:04)Epoch=1,BatchID=1600,Val_AUC=0.7832,Best_Val_AUC=0.7832\n",
      "(00:28:30)Epoch=1,BatchID=1723,Val_AUC=0.7831,Best_Val_AUC=0.7832\n",
      "Reducing learning rate to 0.00100 @ T=3448!\n",
      "Updating regularizer @ T=3448!\n",
      "(00:29:46)Epoch=2,BatchID=0,Val_AUC=0.7831,Best_Val_AUC=0.7832\n",
      "(00:32:38)Epoch=2,BatchID=400,Val_AUC=0.7835,Best_Val_AUC=0.7835\n",
      "(00:35:30)Epoch=2,BatchID=800,Val_AUC=0.7834,Best_Val_AUC=0.7835\n",
      "(00:38:23)Epoch=2,BatchID=1200,Val_AUC=0.7836,Best_Val_AUC=0.7836\n",
      "(00:41:15)Epoch=2,BatchID=1600,Val_AUC=0.7839,Best_Val_AUC=0.7839\n",
      "(00:42:42)Epoch=2,BatchID=1723,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "Reducing learning rate to 0.00010 @ T=5172!\n",
      "Updating regularizer @ T=5172!\n",
      "(00:43:58)Epoch=3,BatchID=0,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(00:46:50)Epoch=3,BatchID=400,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(00:49:43)Epoch=3,BatchID=800,Val_AUC=0.7837,Best_Val_AUC=0.7839\n",
      "(00:52:35)Epoch=3,BatchID=1200,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(00:55:28)Epoch=3,BatchID=1600,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(00:56:53)Epoch=3,BatchID=1723,Val_AUC=0.7837,Best_Val_AUC=0.7839\n",
      "Reducing learning rate to 0.00001 @ T=6896!\n",
      "Updating regularizer @ T=6896!\n",
      "(00:58:10)Epoch=4,BatchID=0,Val_AUC=0.7837,Best_Val_AUC=0.7839\n",
      "(01:01:02)Epoch=4,BatchID=400,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(01:03:55)Epoch=4,BatchID=800,Val_AUC=0.7839,Best_Val_AUC=0.7839\n",
      "(01:06:47)Epoch=4,BatchID=1200,Val_AUC=0.7838,Best_Val_AUC=0.7839\n",
      "(01:09:39)Epoch=4,BatchID=1600,Val_AUC=0.7840,Best_Val_AUC=0.7840\n",
      "(01:11:05)Epoch=4,BatchID=1723,Val_AUC=0.7838,Best_Val_AUC=0.7840\n",
      "Reducing learning rate to 0.00000 @ T=8620!\n",
      "Updating regularizer @ T=8620!\n",
      "(01:12:22)Epoch=5,BatchID=0,Val_AUC=0.7838,Best_Val_AUC=0.7840\n",
      "(01:15:14)Epoch=5,BatchID=400,Val_AUC=0.7839,Best_Val_AUC=0.7840\n",
      "(01:18:06)Epoch=5,BatchID=800,Val_AUC=0.7839,Best_Val_AUC=0.7840\n",
      "(01:20:59)Epoch=5,BatchID=1200,Val_AUC=0.7837,Best_Val_AUC=0.7840\n",
      "(01:23:53)Epoch=5,BatchID=1600,Val_AUC=0.7838,Best_Val_AUC=0.7840\n",
      "(01:25:19)Epoch=5,BatchID=1723,Val_AUC=0.7838,Best_Val_AUC=0.7840\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_female\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True,last_activation=None,activations='relu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model_densenet121.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738af4da-e189-4cd6-904b-cc05f5f90c76",
   "metadata": {},
   "source": [
    "## before40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a9b688-2030-4f5d-8c06-9aaa3086e22f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19562 images in total, 1817 positive images, 17745 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0929\n",
      "\n",
      "Found 19562 images in total, 4292 positive images, 15270 negative images\n",
      "Edema(C1): imbalance ratio is 0.2194\n",
      "\n",
      "Found 19562 images in total, 1250 positive images, 18312 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0639\n",
      "\n",
      "Found 19562 images in total, 4759 positive images, 14803 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2433\n",
      "\n",
      "Found 19562 images in total, 5784 positive images, 13778 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2957\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 2729 images in total, 228 positive images, 2501 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0835\n",
      "\n",
      "Found 2729 images in total, 562 positive images, 2167 negative images\n",
      "Edema(C1): imbalance ratio is 0.2059\n",
      "\n",
      "Found 2729 images in total, 181 positive images, 2548 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0663\n",
      "\n",
      "Found 2729 images in total, 630 positive images, 2099 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2309\n",
      "\n",
      "Found 2729 images in total, 755 positive images, 1974 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2767\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:05)Epoch=0,BatchID=0,Val_AUC=0.4960,Best_Val_AUC=0.4960\n",
      "(00:03:46)Epoch=0,BatchID=400,Val_AUC=0.7251,Best_Val_AUC=0.7251\n",
      "(00:05:28)Epoch=0,BatchID=611,Val_AUC=0.7588,Best_Val_AUC=0.7588\n",
      "Reducing learning rate to 0.01000 @ T=612!\n",
      "Updating regularizer @ T=612!\n",
      "(00:06:33)Epoch=1,BatchID=0,Val_AUC=0.7587,Best_Val_AUC=0.7588\n",
      "(00:09:13)Epoch=1,BatchID=400,Val_AUC=0.7683,Best_Val_AUC=0.7683\n",
      "(00:10:53)Epoch=1,BatchID=611,Val_AUC=0.7718,Best_Val_AUC=0.7718\n",
      "Reducing learning rate to 0.00100 @ T=1224!\n",
      "Updating regularizer @ T=1224!\n",
      "(00:11:58)Epoch=2,BatchID=0,Val_AUC=0.7718,Best_Val_AUC=0.7718\n",
      "(00:14:38)Epoch=2,BatchID=400,Val_AUC=0.7721,Best_Val_AUC=0.7721\n",
      "(00:16:19)Epoch=2,BatchID=611,Val_AUC=0.7721,Best_Val_AUC=0.7721\n",
      "Reducing learning rate to 0.00010 @ T=1836!\n",
      "Updating regularizer @ T=1836!\n",
      "(00:17:24)Epoch=3,BatchID=0,Val_AUC=0.7721,Best_Val_AUC=0.7721\n",
      "(00:20:04)Epoch=3,BatchID=400,Val_AUC=0.7724,Best_Val_AUC=0.7724\n",
      "(00:21:44)Epoch=3,BatchID=611,Val_AUC=0.7724,Best_Val_AUC=0.7724\n",
      "Reducing learning rate to 0.00001 @ T=2448!\n",
      "Updating regularizer @ T=2448!\n",
      "(00:22:49)Epoch=4,BatchID=0,Val_AUC=0.7724,Best_Val_AUC=0.7724\n",
      "(00:25:30)Epoch=4,BatchID=400,Val_AUC=0.7725,Best_Val_AUC=0.7725\n",
      "(00:27:11)Epoch=4,BatchID=611,Val_AUC=0.7724,Best_Val_AUC=0.7725\n",
      "Reducing learning rate to 0.00000 @ T=3060!\n",
      "Updating regularizer @ T=3060!\n",
      "(00:28:16)Epoch=5,BatchID=0,Val_AUC=0.7724,Best_Val_AUC=0.7725\n",
      "(00:30:55)Epoch=5,BatchID=400,Val_AUC=0.7726,Best_Val_AUC=0.7726\n",
      "(00:32:36)Epoch=5,BatchID=611,Val_AUC=0.7725,Best_Val_AUC=0.7726\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_before40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True,last_activation=None,activations='relu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model_densenet121.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7156c-2edf-4897-8db2-92bb27b9c9ae",
   "metadata": {},
   "source": [
    "## after40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d704ab3f-fb47-4c49-9d49-5a408103e6df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 114219 images in total, 14480 positive images, 99739 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1268\n",
      "\n",
      "Found 114219 images in total, 38502 positive images, 75717 negative images\n",
      "Edema(C1): imbalance ratio is 0.3371\n",
      "\n",
      "Found 114219 images in total, 7805 positive images, 106414 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 114219 images in total, 37160 positive images, 77059 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3253\n",
      "\n",
      "Found 114219 images in total, 47891 positive images, 66328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4193\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 16361 images in total, 2014 positive images, 14347 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1231\n",
      "\n",
      "Found 16361 images in total, 5599 positive images, 10762 negative images\n",
      "Edema(C1): imbalance ratio is 0.3422\n",
      "\n",
      "Found 16361 images in total, 1165 positive images, 15196 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0712\n",
      "\n",
      "Found 16361 images in total, 5213 positive images, 11148 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3186\n",
      "\n",
      "Found 16361 images in total, 7007 positive images, 9354 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4283\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:42)Epoch=0,BatchID=0,Val_AUC=0.4845,Best_Val_AUC=0.4845\n",
      "(00:04:57)Epoch=0,BatchID=400,Val_AUC=0.6988,Best_Val_AUC=0.6988\n",
      "(00:08:12)Epoch=0,BatchID=800,Val_AUC=0.7360,Best_Val_AUC=0.7360\n",
      "(00:11:26)Epoch=0,BatchID=1200,Val_AUC=0.7505,Best_Val_AUC=0.7505\n",
      "(00:14:40)Epoch=0,BatchID=1600,Val_AUC=0.7649,Best_Val_AUC=0.7649\n",
      "(00:17:54)Epoch=0,BatchID=2000,Val_AUC=0.7620,Best_Val_AUC=0.7649\n",
      "(00:21:08)Epoch=0,BatchID=2400,Val_AUC=0.7680,Best_Val_AUC=0.7680\n",
      "(00:24:22)Epoch=0,BatchID=2800,Val_AUC=0.7554,Best_Val_AUC=0.7680\n",
      "(00:27:38)Epoch=0,BatchID=3200,Val_AUC=0.7628,Best_Val_AUC=0.7680\n",
      "(00:30:44)Epoch=0,BatchID=3569,Val_AUC=0.7663,Best_Val_AUC=0.7680\n",
      "Reducing learning rate to 0.01000 @ T=3570!\n",
      "Updating regularizer @ T=3570!\n",
      "(00:32:25)Epoch=1,BatchID=0,Val_AUC=0.7666,Best_Val_AUC=0.7680\n",
      "(00:35:39)Epoch=1,BatchID=400,Val_AUC=0.7810,Best_Val_AUC=0.7810\n",
      "(00:38:53)Epoch=1,BatchID=800,Val_AUC=0.7819,Best_Val_AUC=0.7819\n",
      "(00:42:07)Epoch=1,BatchID=1200,Val_AUC=0.7825,Best_Val_AUC=0.7825\n",
      "(00:45:22)Epoch=1,BatchID=1600,Val_AUC=0.7835,Best_Val_AUC=0.7835\n",
      "(00:48:37)Epoch=1,BatchID=2000,Val_AUC=0.7851,Best_Val_AUC=0.7851\n",
      "(00:51:52)Epoch=1,BatchID=2400,Val_AUC=0.7849,Best_Val_AUC=0.7851\n",
      "(00:55:06)Epoch=1,BatchID=2800,Val_AUC=0.7851,Best_Val_AUC=0.7851\n",
      "(00:58:20)Epoch=1,BatchID=3200,Val_AUC=0.7867,Best_Val_AUC=0.7867\n",
      "(01:01:25)Epoch=1,BatchID=3569,Val_AUC=0.7862,Best_Val_AUC=0.7867\n",
      "Reducing learning rate to 0.00100 @ T=7140!\n",
      "Updating regularizer @ T=7140!\n",
      "(01:03:04)Epoch=2,BatchID=0,Val_AUC=0.7863,Best_Val_AUC=0.7867\n",
      "(01:06:18)Epoch=2,BatchID=400,Val_AUC=0.7868,Best_Val_AUC=0.7868\n",
      "(01:09:32)Epoch=2,BatchID=800,Val_AUC=0.7870,Best_Val_AUC=0.7870\n",
      "(01:12:47)Epoch=2,BatchID=1200,Val_AUC=0.7871,Best_Val_AUC=0.7871\n",
      "(01:16:01)Epoch=2,BatchID=1600,Val_AUC=0.7872,Best_Val_AUC=0.7872\n",
      "(01:19:15)Epoch=2,BatchID=2000,Val_AUC=0.7873,Best_Val_AUC=0.7873\n",
      "(01:22:28)Epoch=2,BatchID=2400,Val_AUC=0.7875,Best_Val_AUC=0.7875\n",
      "(01:25:43)Epoch=2,BatchID=2800,Val_AUC=0.7877,Best_Val_AUC=0.7877\n",
      "(01:28:58)Epoch=2,BatchID=3200,Val_AUC=0.7878,Best_Val_AUC=0.7878\n",
      "(01:32:02)Epoch=2,BatchID=3569,Val_AUC=0.7878,Best_Val_AUC=0.7878\n",
      "Reducing learning rate to 0.00010 @ T=10710!\n",
      "Updating regularizer @ T=10710!\n",
      "(01:33:42)Epoch=3,BatchID=0,Val_AUC=0.7878,Best_Val_AUC=0.7878\n",
      "(01:36:56)Epoch=3,BatchID=400,Val_AUC=0.7878,Best_Val_AUC=0.7878\n",
      "(01:40:10)Epoch=3,BatchID=800,Val_AUC=0.7879,Best_Val_AUC=0.7879\n",
      "(01:43:24)Epoch=3,BatchID=1200,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(01:46:39)Epoch=3,BatchID=1600,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(01:49:52)Epoch=3,BatchID=2000,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(01:53:03)Epoch=3,BatchID=2400,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(01:56:16)Epoch=3,BatchID=2800,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(01:59:30)Epoch=3,BatchID=3200,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:02:33)Epoch=3,BatchID=3569,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "Reducing learning rate to 0.00001 @ T=14280!\n",
      "Updating regularizer @ T=14280!\n",
      "(02:04:12)Epoch=4,BatchID=0,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:07:24)Epoch=4,BatchID=400,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:10:37)Epoch=4,BatchID=800,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:13:49)Epoch=4,BatchID=1200,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:17:02)Epoch=4,BatchID=1600,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:20:14)Epoch=4,BatchID=2000,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:23:28)Epoch=4,BatchID=2400,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:27:02)Epoch=4,BatchID=2800,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:30:44)Epoch=4,BatchID=3200,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(02:33:50)Epoch=4,BatchID=3569,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "Reducing learning rate to 0.00000 @ T=17850!\n",
      "Updating regularizer @ T=17850!\n",
      "(02:35:30)Epoch=5,BatchID=0,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(02:38:46)Epoch=5,BatchID=400,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(02:41:59)Epoch=5,BatchID=800,Val_AUC=0.7878,Best_Val_AUC=0.7880\n",
      "(02:45:12)Epoch=5,BatchID=1200,Val_AUC=0.7879,Best_Val_AUC=0.7880\n",
      "(02:48:24)Epoch=5,BatchID=1600,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:51:38)Epoch=5,BatchID=2000,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:54:54)Epoch=5,BatchID=2400,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(02:58:11)Epoch=5,BatchID=2800,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(03:01:26)Epoch=5,BatchID=3200,Val_AUC=0.7880,Best_Val_AUC=0.7880\n",
      "(03:04:29)Epoch=5,BatchID=3569,Val_AUC=0.7880,Best_Val_AUC=0.7880\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_after40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = DenseNet121(pretrained=True,last_activation=None,activations='relu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model_densenet121.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7e86e-f214-4aa0-872d-6595e96561d6",
   "metadata": {},
   "source": [
    "# Resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99bd6e-c5f1-41a1-be8f-b52e54c7f73d",
   "metadata": {},
   "source": [
    "## Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8657357-303d-4d49-9fa8-02857ad44acc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 133781 images in total, 16297 positive images, 117484 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1218\n",
      "\n",
      "Found 133781 images in total, 42794 positive images, 90987 negative images\n",
      "Edema(C1): imbalance ratio is 0.3199\n",
      "\n",
      "Found 133781 images in total, 9055 positive images, 124726 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0677\n",
      "\n",
      "Found 133781 images in total, 41919 positive images, 91862 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3133\n",
      "\n",
      "Found 133781 images in total, 53675 positive images, 80106 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4012\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19090 images in total, 2242 positive images, 16848 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1174\n",
      "\n",
      "Found 19090 images in total, 6161 positive images, 12929 negative images\n",
      "Edema(C1): imbalance ratio is 0.3227\n",
      "\n",
      "Found 19090 images in total, 1346 positive images, 17744 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0705\n",
      "\n",
      "Found 19090 images in total, 5843 positive images, 13247 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3061\n",
      "\n",
      "Found 19090 images in total, 7762 positive images, 11328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to C:\\Users\\moc90/.cache\\torch\\hub\\checkpoints\\resnet34-333f7ec4.pth\n",
      "100%|| 83.3M/83.3M [00:07<00:00, 11.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "------------------------------\n",
      "(00:01:49)Epoch=0,BatchID=0,Val_AUC=0.4747,Best_Val_AUC=0.4747\n",
      "(00:03:59)Epoch=0,BatchID=400,Val_AUC=0.7122,Best_Val_AUC=0.7122\n",
      "(00:06:07)Epoch=0,BatchID=800,Val_AUC=0.7286,Best_Val_AUC=0.7286\n",
      "(00:08:15)Epoch=0,BatchID=1200,Val_AUC=0.7269,Best_Val_AUC=0.7286\n",
      "(00:10:25)Epoch=0,BatchID=1600,Val_AUC=0.7446,Best_Val_AUC=0.7446\n",
      "(00:12:33)Epoch=0,BatchID=2000,Val_AUC=0.7470,Best_Val_AUC=0.7470\n",
      "(00:14:43)Epoch=0,BatchID=2400,Val_AUC=0.7474,Best_Val_AUC=0.7474\n",
      "(00:16:51)Epoch=0,BatchID=2800,Val_AUC=0.7417,Best_Val_AUC=0.7474\n",
      "(00:19:01)Epoch=0,BatchID=3200,Val_AUC=0.7440,Best_Val_AUC=0.7474\n",
      "(00:21:11)Epoch=0,BatchID=3600,Val_AUC=0.7463,Best_Val_AUC=0.7474\n",
      "(00:23:21)Epoch=0,BatchID=4000,Val_AUC=0.7457,Best_Val_AUC=0.7474\n",
      "(00:24:58)Epoch=0,BatchID=4180,Val_AUC=0.7427,Best_Val_AUC=0.7474\n",
      "Reducing learning rate to 0.01000 @ T=4181!\n",
      "Updating regularizer @ T=4181!\n",
      "(00:26:39)Epoch=1,BatchID=0,Val_AUC=0.7435,Best_Val_AUC=0.7474\n",
      "(00:28:47)Epoch=1,BatchID=400,Val_AUC=0.7607,Best_Val_AUC=0.7607\n",
      "(00:30:55)Epoch=1,BatchID=800,Val_AUC=0.7633,Best_Val_AUC=0.7633\n",
      "(00:33:08)Epoch=1,BatchID=1200,Val_AUC=0.7641,Best_Val_AUC=0.7641\n",
      "(00:35:16)Epoch=1,BatchID=1600,Val_AUC=0.7641,Best_Val_AUC=0.7641\n",
      "(00:37:26)Epoch=1,BatchID=2000,Val_AUC=0.7651,Best_Val_AUC=0.7651\n",
      "(00:39:36)Epoch=1,BatchID=2400,Val_AUC=0.7657,Best_Val_AUC=0.7657\n",
      "(00:41:46)Epoch=1,BatchID=2800,Val_AUC=0.7654,Best_Val_AUC=0.7657\n",
      "(00:43:54)Epoch=1,BatchID=3200,Val_AUC=0.7650,Best_Val_AUC=0.7657\n",
      "(00:46:04)Epoch=1,BatchID=3600,Val_AUC=0.7681,Best_Val_AUC=0.7681\n",
      "(00:48:14)Epoch=1,BatchID=4000,Val_AUC=0.7679,Best_Val_AUC=0.7681\n",
      "(00:49:52)Epoch=1,BatchID=4180,Val_AUC=0.7676,Best_Val_AUC=0.7681\n",
      "Reducing learning rate to 0.00100 @ T=8362!\n",
      "Updating regularizer @ T=8362!\n",
      "(00:51:31)Epoch=2,BatchID=0,Val_AUC=0.7678,Best_Val_AUC=0.7681\n",
      "(00:53:42)Epoch=2,BatchID=400,Val_AUC=0.7701,Best_Val_AUC=0.7701\n",
      "(00:55:52)Epoch=2,BatchID=800,Val_AUC=0.7703,Best_Val_AUC=0.7703\n",
      "(00:58:01)Epoch=2,BatchID=1200,Val_AUC=0.7705,Best_Val_AUC=0.7705\n",
      "(01:00:12)Epoch=2,BatchID=1600,Val_AUC=0.7707,Best_Val_AUC=0.7707\n",
      "(01:02:30)Epoch=2,BatchID=2000,Val_AUC=0.7708,Best_Val_AUC=0.7708\n",
      "(01:04:44)Epoch=2,BatchID=2400,Val_AUC=0.7710,Best_Val_AUC=0.7710\n",
      "(01:06:57)Epoch=2,BatchID=2800,Val_AUC=0.7711,Best_Val_AUC=0.7711\n",
      "(01:09:12)Epoch=2,BatchID=3200,Val_AUC=0.7710,Best_Val_AUC=0.7711\n",
      "(01:11:21)Epoch=2,BatchID=3600,Val_AUC=0.7712,Best_Val_AUC=0.7712\n",
      "(01:13:29)Epoch=2,BatchID=4000,Val_AUC=0.7715,Best_Val_AUC=0.7715\n",
      "(01:15:06)Epoch=2,BatchID=4180,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "Reducing learning rate to 0.00010 @ T=12543!\n",
      "Updating regularizer @ T=12543!\n",
      "(01:16:47)Epoch=3,BatchID=0,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:18:57)Epoch=3,BatchID=400,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:21:07)Epoch=3,BatchID=800,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:23:18)Epoch=3,BatchID=1200,Val_AUC=0.7715,Best_Val_AUC=0.7716\n",
      "(01:25:31)Epoch=3,BatchID=1600,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:27:45)Epoch=3,BatchID=2000,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:30:00)Epoch=3,BatchID=2400,Val_AUC=0.7713,Best_Val_AUC=0.7716\n",
      "(01:32:13)Epoch=3,BatchID=2800,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:34:24)Epoch=3,BatchID=3200,Val_AUC=0.7715,Best_Val_AUC=0.7716\n",
      "(01:36:33)Epoch=3,BatchID=3600,Val_AUC=0.7715,Best_Val_AUC=0.7716\n",
      "(01:38:43)Epoch=3,BatchID=4000,Val_AUC=0.7716,Best_Val_AUC=0.7716\n",
      "(01:40:21)Epoch=3,BatchID=4180,Val_AUC=0.7714,Best_Val_AUC=0.7716\n",
      "Reducing learning rate to 0.00001 @ T=16724!\n",
      "Updating regularizer @ T=16724!\n",
      "(01:42:01)Epoch=4,BatchID=0,Val_AUC=0.7715,Best_Val_AUC=0.7716\n",
      "(01:44:10)Epoch=4,BatchID=400,Val_AUC=0.7715,Best_Val_AUC=0.7716\n",
      "(01:46:18)Epoch=4,BatchID=800,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(01:48:28)Epoch=4,BatchID=1200,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(01:50:38)Epoch=4,BatchID=1600,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(01:52:46)Epoch=4,BatchID=2000,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(01:54:56)Epoch=4,BatchID=2400,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(01:57:06)Epoch=4,BatchID=2800,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(01:59:16)Epoch=4,BatchID=3200,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(02:01:24)Epoch=4,BatchID=3600,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(02:03:37)Epoch=4,BatchID=4000,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(02:05:17)Epoch=4,BatchID=4180,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "Reducing learning rate to 0.00000 @ T=20905!\n",
      "Updating regularizer @ T=20905!\n",
      "(02:06:59)Epoch=5,BatchID=0,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(02:09:11)Epoch=5,BatchID=400,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(02:11:24)Epoch=5,BatchID=800,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(02:13:34)Epoch=5,BatchID=1200,Val_AUC=0.7717,Best_Val_AUC=0.7717\n",
      "(02:15:46)Epoch=5,BatchID=1600,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:17:56)Epoch=5,BatchID=2000,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:20:04)Epoch=5,BatchID=2400,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:22:17)Epoch=5,BatchID=2800,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:24:29)Epoch=5,BatchID=3200,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:26:38)Epoch=5,BatchID=3600,Val_AUC=0.7716,Best_Val_AUC=0.7717\n",
      "(02:28:50)Epoch=5,BatchID=4000,Val_AUC=0.7715,Best_Val_AUC=0.7717\n",
      "(02:30:27)Epoch=5,BatchID=4180,Val_AUC=0.7716,Best_Val_AUC=0.7717\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_origin\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED) \n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "                \n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf9b6a-c7eb-44d3-9289-aad81abe5cdc",
   "metadata": {},
   "source": [
    "## Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f8acca-ff52-4103-a354-83e478d55c6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 78644 images in total, 9943 positive images, 68701 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1264\n",
      "\n",
      "Found 78644 images in total, 24591 positive images, 54053 negative images\n",
      "Edema(C1): imbalance ratio is 0.3127\n",
      "\n",
      "Found 78644 images in total, 5314 positive images, 73330 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0676\n",
      "\n",
      "Found 78644 images in total, 24764 positive images, 53880 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3149\n",
      "\n",
      "Found 78644 images in total, 31305 positive images, 47339 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3981\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 11159 images in total, 1392 positive images, 9767 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1247\n",
      "\n",
      "Found 11159 images in total, 3541 positive images, 7618 negative images\n",
      "Edema(C1): imbalance ratio is 0.3173\n",
      "\n",
      "Found 11159 images in total, 762 positive images, 10397 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 11159 images in total, 3527 positive images, 7632 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3161\n",
      "\n",
      "Found 11159 images in total, 4573 positive images, 6586 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4098\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:27)Epoch=0,BatchID=0,Val_AUC=0.4744,Best_Val_AUC=0.4744\n",
      "(00:03:18)Epoch=0,BatchID=400,Val_AUC=0.7194,Best_Val_AUC=0.7194\n",
      "(00:05:12)Epoch=0,BatchID=800,Val_AUC=0.7379,Best_Val_AUC=0.7379\n",
      "(00:07:05)Epoch=0,BatchID=1200,Val_AUC=0.7377,Best_Val_AUC=0.7379\n",
      "(00:09:00)Epoch=0,BatchID=1600,Val_AUC=0.7393,Best_Val_AUC=0.7393\n",
      "(00:10:51)Epoch=0,BatchID=2000,Val_AUC=0.7508,Best_Val_AUC=0.7508\n",
      "(00:12:42)Epoch=0,BatchID=2400,Val_AUC=0.7421,Best_Val_AUC=0.7508\n",
      "(00:13:43)Epoch=0,BatchID=2457,Val_AUC=0.7468,Best_Val_AUC=0.7508\n",
      "Reducing learning rate to 0.01000 @ T=2458!\n",
      "Updating regularizer @ T=2458!\n",
      "(00:15:05)Epoch=1,BatchID=0,Val_AUC=0.7478,Best_Val_AUC=0.7508\n",
      "(00:16:56)Epoch=1,BatchID=400,Val_AUC=0.7624,Best_Val_AUC=0.7624\n",
      "(00:18:46)Epoch=1,BatchID=800,Val_AUC=0.7637,Best_Val_AUC=0.7637\n",
      "(00:20:37)Epoch=1,BatchID=1200,Val_AUC=0.7656,Best_Val_AUC=0.7656\n",
      "(00:22:26)Epoch=1,BatchID=1600,Val_AUC=0.7661,Best_Val_AUC=0.7661\n",
      "(00:24:17)Epoch=1,BatchID=2000,Val_AUC=0.7671,Best_Val_AUC=0.7671\n",
      "(00:26:08)Epoch=1,BatchID=2400,Val_AUC=0.7667,Best_Val_AUC=0.7671\n",
      "(00:27:08)Epoch=1,BatchID=2457,Val_AUC=0.7683,Best_Val_AUC=0.7683\n",
      "Reducing learning rate to 0.00100 @ T=4916!\n",
      "Updating regularizer @ T=4916!\n",
      "(00:28:29)Epoch=2,BatchID=0,Val_AUC=0.7683,Best_Val_AUC=0.7683\n",
      "(00:30:19)Epoch=2,BatchID=400,Val_AUC=0.7689,Best_Val_AUC=0.7689\n",
      "(00:32:10)Epoch=2,BatchID=800,Val_AUC=0.7693,Best_Val_AUC=0.7693\n",
      "(00:34:01)Epoch=2,BatchID=1200,Val_AUC=0.7694,Best_Val_AUC=0.7694\n",
      "(00:35:50)Epoch=2,BatchID=1600,Val_AUC=0.7692,Best_Val_AUC=0.7694\n",
      "(00:37:42)Epoch=2,BatchID=2000,Val_AUC=0.7695,Best_Val_AUC=0.7695\n",
      "(00:39:33)Epoch=2,BatchID=2400,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:40:33)Epoch=2,BatchID=2457,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "Reducing learning rate to 0.00010 @ T=7374!\n",
      "Updating regularizer @ T=7374!\n",
      "(00:41:55)Epoch=3,BatchID=0,Val_AUC=0.7696,Best_Val_AUC=0.7697\n",
      "(00:43:46)Epoch=3,BatchID=400,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:45:37)Epoch=3,BatchID=800,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:47:28)Epoch=3,BatchID=1200,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:49:20)Epoch=3,BatchID=1600,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:51:10)Epoch=3,BatchID=2000,Val_AUC=0.7696,Best_Val_AUC=0.7697\n",
      "(00:53:01)Epoch=3,BatchID=2400,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:54:02)Epoch=3,BatchID=2457,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "Reducing learning rate to 0.00001 @ T=9832!\n",
      "Updating regularizer @ T=9832!\n",
      "(00:55:24)Epoch=4,BatchID=0,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:57:15)Epoch=4,BatchID=400,Val_AUC=0.7697,Best_Val_AUC=0.7697\n",
      "(00:59:06)Epoch=4,BatchID=800,Val_AUC=0.7698,Best_Val_AUC=0.7698\n",
      "(01:00:58)Epoch=4,BatchID=1200,Val_AUC=0.7697,Best_Val_AUC=0.7698\n",
      "(01:02:52)Epoch=4,BatchID=1600,Val_AUC=0.7697,Best_Val_AUC=0.7698\n",
      "(01:04:42)Epoch=4,BatchID=2000,Val_AUC=0.7697,Best_Val_AUC=0.7698\n",
      "(01:06:33)Epoch=4,BatchID=2400,Val_AUC=0.7697,Best_Val_AUC=0.7698\n",
      "(01:07:34)Epoch=4,BatchID=2457,Val_AUC=0.7699,Best_Val_AUC=0.7699\n",
      "Reducing learning rate to 0.00000 @ T=12290!\n",
      "Updating regularizer @ T=12290!\n",
      "(01:08:57)Epoch=5,BatchID=0,Val_AUC=0.7699,Best_Val_AUC=0.7699\n",
      "(01:10:49)Epoch=5,BatchID=400,Val_AUC=0.7697,Best_Val_AUC=0.7699\n",
      "(01:12:40)Epoch=5,BatchID=800,Val_AUC=0.7698,Best_Val_AUC=0.7699\n",
      "(01:14:32)Epoch=5,BatchID=1200,Val_AUC=0.7697,Best_Val_AUC=0.7699\n",
      "(01:16:24)Epoch=5,BatchID=1600,Val_AUC=0.7698,Best_Val_AUC=0.7699\n",
      "(01:18:16)Epoch=5,BatchID=2000,Val_AUC=0.7698,Best_Val_AUC=0.7699\n",
      "(01:20:08)Epoch=5,BatchID=2400,Val_AUC=0.7697,Best_Val_AUC=0.7699\n",
      "(01:21:10)Epoch=5,BatchID=2457,Val_AUC=0.7698,Best_Val_AUC=0.7699\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_male\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a4995-d5f3-415f-afc7-4a7d8757834e",
   "metadata": {},
   "source": [
    "## Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7fe068f-ff42-4c44-a301-e19085a21e8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 55137 images in total, 6354 positive images, 48783 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1152\n",
      "\n",
      "Found 55137 images in total, 18203 positive images, 36934 negative images\n",
      "Edema(C1): imbalance ratio is 0.3301\n",
      "\n",
      "Found 55137 images in total, 3741 positive images, 51396 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0678\n",
      "\n",
      "Found 55137 images in total, 17155 positive images, 37982 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3111\n",
      "\n",
      "Found 55137 images in total, 22370 positive images, 32767 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4057\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 7931 images in total, 850 positive images, 7081 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1072\n",
      "\n",
      "Found 7931 images in total, 2620 positive images, 5311 negative images\n",
      "Edema(C1): imbalance ratio is 0.3303\n",
      "\n",
      "Found 7931 images in total, 584 positive images, 7347 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0736\n",
      "\n",
      "Found 7931 images in total, 2316 positive images, 5615 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2920\n",
      "\n",
      "Found 7931 images in total, 3189 positive images, 4742 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4021\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:17)Epoch=0,BatchID=0,Val_AUC=0.4731,Best_Val_AUC=0.4731\n",
      "(00:03:02)Epoch=0,BatchID=400,Val_AUC=0.7165,Best_Val_AUC=0.7165\n",
      "(00:04:46)Epoch=0,BatchID=800,Val_AUC=0.7351,Best_Val_AUC=0.7351\n",
      "(00:06:30)Epoch=0,BatchID=1200,Val_AUC=0.7390,Best_Val_AUC=0.7390\n",
      "(00:08:13)Epoch=0,BatchID=1600,Val_AUC=0.7386,Best_Val_AUC=0.7390\n",
      "(00:09:17)Epoch=0,BatchID=1723,Val_AUC=0.7463,Best_Val_AUC=0.7463\n",
      "Reducing learning rate to 0.01000 @ T=1724!\n",
      "Updating regularizer @ T=1724!\n",
      "(00:10:31)Epoch=1,BatchID=0,Val_AUC=0.7467,Best_Val_AUC=0.7467\n",
      "(00:12:15)Epoch=1,BatchID=400,Val_AUC=0.7584,Best_Val_AUC=0.7584\n",
      "(00:14:00)Epoch=1,BatchID=800,Val_AUC=0.7600,Best_Val_AUC=0.7600\n",
      "(00:15:43)Epoch=1,BatchID=1200,Val_AUC=0.7614,Best_Val_AUC=0.7614\n",
      "(00:17:28)Epoch=1,BatchID=1600,Val_AUC=0.7628,Best_Val_AUC=0.7628\n",
      "(00:18:33)Epoch=1,BatchID=1723,Val_AUC=0.7631,Best_Val_AUC=0.7631\n",
      "Reducing learning rate to 0.00100 @ T=3448!\n",
      "Updating regularizer @ T=3448!\n",
      "(00:19:48)Epoch=2,BatchID=0,Val_AUC=0.7632,Best_Val_AUC=0.7632\n",
      "(00:21:34)Epoch=2,BatchID=400,Val_AUC=0.7638,Best_Val_AUC=0.7638\n",
      "(00:23:21)Epoch=2,BatchID=800,Val_AUC=0.7641,Best_Val_AUC=0.7641\n",
      "(00:25:07)Epoch=2,BatchID=1200,Val_AUC=0.7646,Best_Val_AUC=0.7646\n",
      "(00:26:52)Epoch=2,BatchID=1600,Val_AUC=0.7645,Best_Val_AUC=0.7646\n",
      "(00:27:57)Epoch=2,BatchID=1723,Val_AUC=0.7645,Best_Val_AUC=0.7646\n",
      "Reducing learning rate to 0.00010 @ T=5172!\n",
      "Updating regularizer @ T=5172!\n",
      "(00:29:13)Epoch=3,BatchID=0,Val_AUC=0.7647,Best_Val_AUC=0.7647\n",
      "(00:30:58)Epoch=3,BatchID=400,Val_AUC=0.7646,Best_Val_AUC=0.7647\n",
      "(00:32:43)Epoch=3,BatchID=800,Val_AUC=0.7647,Best_Val_AUC=0.7647\n",
      "(00:34:27)Epoch=3,BatchID=1200,Val_AUC=0.7648,Best_Val_AUC=0.7648\n",
      "(00:36:11)Epoch=3,BatchID=1600,Val_AUC=0.7650,Best_Val_AUC=0.7650\n",
      "(00:37:13)Epoch=3,BatchID=1723,Val_AUC=0.7649,Best_Val_AUC=0.7650\n",
      "Reducing learning rate to 0.00001 @ T=6896!\n",
      "Updating regularizer @ T=6896!\n",
      "(00:38:28)Epoch=4,BatchID=0,Val_AUC=0.7648,Best_Val_AUC=0.7650\n",
      "(00:40:11)Epoch=4,BatchID=400,Val_AUC=0.7648,Best_Val_AUC=0.7650\n",
      "(00:41:55)Epoch=4,BatchID=800,Val_AUC=0.7644,Best_Val_AUC=0.7650\n",
      "(00:43:38)Epoch=4,BatchID=1200,Val_AUC=0.7647,Best_Val_AUC=0.7650\n",
      "(00:45:22)Epoch=4,BatchID=1600,Val_AUC=0.7645,Best_Val_AUC=0.7650\n",
      "(00:46:24)Epoch=4,BatchID=1723,Val_AUC=0.7649,Best_Val_AUC=0.7650\n",
      "Reducing learning rate to 0.00000 @ T=8620!\n",
      "Updating regularizer @ T=8620!\n",
      "(00:47:39)Epoch=5,BatchID=0,Val_AUC=0.7650,Best_Val_AUC=0.7650\n",
      "(00:49:22)Epoch=5,BatchID=400,Val_AUC=0.7649,Best_Val_AUC=0.7650\n",
      "(00:51:05)Epoch=5,BatchID=800,Val_AUC=0.7648,Best_Val_AUC=0.7650\n",
      "(00:52:49)Epoch=5,BatchID=1200,Val_AUC=0.7643,Best_Val_AUC=0.7650\n",
      "(00:54:34)Epoch=5,BatchID=1600,Val_AUC=0.7647,Best_Val_AUC=0.7650\n",
      "(00:55:38)Epoch=5,BatchID=1723,Val_AUC=0.7647,Best_Val_AUC=0.7650\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_female\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162afee-ad90-483c-95e7-086a06af617d",
   "metadata": {},
   "source": [
    "## before40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2bed5c0-88c7-40bb-b86a-704dabee8e6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19562 images in total, 1817 positive images, 17745 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0929\n",
      "\n",
      "Found 19562 images in total, 4292 positive images, 15270 negative images\n",
      "Edema(C1): imbalance ratio is 0.2194\n",
      "\n",
      "Found 19562 images in total, 1250 positive images, 18312 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0639\n",
      "\n",
      "Found 19562 images in total, 4759 positive images, 14803 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2433\n",
      "\n",
      "Found 19562 images in total, 5784 positive images, 13778 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2957\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 2729 images in total, 228 positive images, 2501 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0835\n",
      "\n",
      "Found 2729 images in total, 562 positive images, 2167 negative images\n",
      "Edema(C1): imbalance ratio is 0.2059\n",
      "\n",
      "Found 2729 images in total, 181 positive images, 2548 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0663\n",
      "\n",
      "Found 2729 images in total, 630 positive images, 2099 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2309\n",
      "\n",
      "Found 2729 images in total, 755 positive images, 1974 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2767\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:03)Epoch=0,BatchID=0,Val_AUC=0.4593,Best_Val_AUC=0.4593\n",
      "(00:02:36)Epoch=0,BatchID=400,Val_AUC=0.7438,Best_Val_AUC=0.7438\n",
      "(00:03:41)Epoch=0,BatchID=611,Val_AUC=0.7588,Best_Val_AUC=0.7588\n",
      "Reducing learning rate to 0.01000 @ T=612!\n",
      "Updating regularizer @ T=612!\n",
      "(00:04:44)Epoch=1,BatchID=0,Val_AUC=0.7590,Best_Val_AUC=0.7590\n",
      "(00:06:16)Epoch=1,BatchID=400,Val_AUC=0.7712,Best_Val_AUC=0.7712\n",
      "(00:07:20)Epoch=1,BatchID=611,Val_AUC=0.7728,Best_Val_AUC=0.7728\n",
      "Reducing learning rate to 0.00100 @ T=1224!\n",
      "Updating regularizer @ T=1224!\n",
      "(00:08:23)Epoch=2,BatchID=0,Val_AUC=0.7727,Best_Val_AUC=0.7728\n",
      "(00:09:55)Epoch=2,BatchID=400,Val_AUC=0.7732,Best_Val_AUC=0.7732\n",
      "(00:10:59)Epoch=2,BatchID=611,Val_AUC=0.7732,Best_Val_AUC=0.7732\n",
      "Reducing learning rate to 0.00010 @ T=1836!\n",
      "Updating regularizer @ T=1836!\n",
      "(00:12:02)Epoch=3,BatchID=0,Val_AUC=0.7732,Best_Val_AUC=0.7732\n",
      "(00:13:33)Epoch=3,BatchID=400,Val_AUC=0.7733,Best_Val_AUC=0.7733\n",
      "(00:14:37)Epoch=3,BatchID=611,Val_AUC=0.7735,Best_Val_AUC=0.7735\n",
      "Reducing learning rate to 0.00001 @ T=2448!\n",
      "Updating regularizer @ T=2448!\n",
      "(00:15:40)Epoch=4,BatchID=0,Val_AUC=0.7735,Best_Val_AUC=0.7735\n",
      "(00:17:11)Epoch=4,BatchID=400,Val_AUC=0.7733,Best_Val_AUC=0.7735\n",
      "(00:18:15)Epoch=4,BatchID=611,Val_AUC=0.7735,Best_Val_AUC=0.7735\n",
      "Reducing learning rate to 0.00000 @ T=3060!\n",
      "Updating regularizer @ T=3060!\n",
      "(00:19:17)Epoch=5,BatchID=0,Val_AUC=0.7735,Best_Val_AUC=0.7735\n",
      "(00:20:49)Epoch=5,BatchID=400,Val_AUC=0.7732,Best_Val_AUC=0.7735\n",
      "(00:21:53)Epoch=5,BatchID=611,Val_AUC=0.7734,Best_Val_AUC=0.7735\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_before40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782550b1-cad9-4cfb-8a74-d7c5312e1d70",
   "metadata": {},
   "source": [
    "## after40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47e116d-e17d-4487-9e61-d8a0a2dcc130",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 114219 images in total, 14480 positive images, 99739 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1268\n",
      "\n",
      "Found 114219 images in total, 38502 positive images, 75717 negative images\n",
      "Edema(C1): imbalance ratio is 0.3371\n",
      "\n",
      "Found 114219 images in total, 7805 positive images, 106414 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 114219 images in total, 37160 positive images, 77059 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3253\n",
      "\n",
      "Found 114219 images in total, 47891 positive images, 66328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4193\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 16361 images in total, 2014 positive images, 14347 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1231\n",
      "\n",
      "Found 16361 images in total, 5599 positive images, 10762 negative images\n",
      "Edema(C1): imbalance ratio is 0.3422\n",
      "\n",
      "Found 16361 images in total, 1165 positive images, 15196 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0712\n",
      "\n",
      "Found 16361 images in total, 5213 positive images, 11148 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3186\n",
      "\n",
      "Found 16361 images in total, 7007 positive images, 9354 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4283\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:41)Epoch=0,BatchID=0,Val_AUC=0.4732,Best_Val_AUC=0.4732\n",
      "(00:03:42)Epoch=0,BatchID=400,Val_AUC=0.7089,Best_Val_AUC=0.7089\n",
      "(00:05:45)Epoch=0,BatchID=800,Val_AUC=0.7186,Best_Val_AUC=0.7186\n",
      "(00:07:48)Epoch=0,BatchID=1200,Val_AUC=0.7335,Best_Val_AUC=0.7335\n",
      "(00:09:52)Epoch=0,BatchID=1600,Val_AUC=0.7348,Best_Val_AUC=0.7348\n",
      "(00:11:54)Epoch=0,BatchID=2000,Val_AUC=0.7332,Best_Val_AUC=0.7348\n",
      "(00:13:55)Epoch=0,BatchID=2400,Val_AUC=0.7419,Best_Val_AUC=0.7419\n",
      "(00:15:58)Epoch=0,BatchID=2800,Val_AUC=0.7382,Best_Val_AUC=0.7419\n",
      "(00:18:00)Epoch=0,BatchID=3200,Val_AUC=0.7351,Best_Val_AUC=0.7419\n",
      "(00:19:58)Epoch=0,BatchID=3569,Val_AUC=0.7342,Best_Val_AUC=0.7419\n",
      "Reducing learning rate to 0.01000 @ T=3570!\n",
      "Updating regularizer @ T=3570!\n",
      "(00:21:30)Epoch=1,BatchID=0,Val_AUC=0.7354,Best_Val_AUC=0.7419\n",
      "(00:23:31)Epoch=1,BatchID=400,Val_AUC=0.7537,Best_Val_AUC=0.7537\n",
      "(00:25:33)Epoch=1,BatchID=800,Val_AUC=0.7553,Best_Val_AUC=0.7553\n",
      "(00:27:37)Epoch=1,BatchID=1200,Val_AUC=0.7565,Best_Val_AUC=0.7565\n",
      "(00:29:39)Epoch=1,BatchID=1600,Val_AUC=0.7575,Best_Val_AUC=0.7575\n",
      "(00:31:42)Epoch=1,BatchID=2000,Val_AUC=0.7591,Best_Val_AUC=0.7591\n",
      "(00:33:44)Epoch=1,BatchID=2400,Val_AUC=0.7577,Best_Val_AUC=0.7591\n",
      "(00:35:46)Epoch=1,BatchID=2800,Val_AUC=0.7601,Best_Val_AUC=0.7601\n",
      "(00:37:48)Epoch=1,BatchID=3200,Val_AUC=0.7595,Best_Val_AUC=0.7601\n",
      "(00:39:46)Epoch=1,BatchID=3569,Val_AUC=0.7607,Best_Val_AUC=0.7607\n",
      "Reducing learning rate to 0.00100 @ T=7140!\n",
      "Updating regularizer @ T=7140!\n",
      "(00:41:18)Epoch=2,BatchID=0,Val_AUC=0.7607,Best_Val_AUC=0.7607\n",
      "(00:43:20)Epoch=2,BatchID=400,Val_AUC=0.7619,Best_Val_AUC=0.7619\n",
      "(00:45:22)Epoch=2,BatchID=800,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "(00:47:26)Epoch=2,BatchID=1200,Val_AUC=0.7624,Best_Val_AUC=0.7624\n",
      "(00:49:28)Epoch=2,BatchID=1600,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(00:51:31)Epoch=2,BatchID=2000,Val_AUC=0.7627,Best_Val_AUC=0.7627\n",
      "(00:53:33)Epoch=2,BatchID=2400,Val_AUC=0.7627,Best_Val_AUC=0.7627\n",
      "(00:55:37)Epoch=2,BatchID=2800,Val_AUC=0.7630,Best_Val_AUC=0.7630\n",
      "(00:57:40)Epoch=2,BatchID=3200,Val_AUC=0.7633,Best_Val_AUC=0.7633\n",
      "(00:59:37)Epoch=2,BatchID=3569,Val_AUC=0.7632,Best_Val_AUC=0.7633\n",
      "Reducing learning rate to 0.00010 @ T=10710!\n",
      "Updating regularizer @ T=10710!\n",
      "(01:01:07)Epoch=3,BatchID=0,Val_AUC=0.7632,Best_Val_AUC=0.7633\n",
      "(01:03:08)Epoch=3,BatchID=400,Val_AUC=0.7633,Best_Val_AUC=0.7633\n",
      "(01:05:10)Epoch=3,BatchID=800,Val_AUC=0.7632,Best_Val_AUC=0.7633\n",
      "(01:07:13)Epoch=3,BatchID=1200,Val_AUC=0.7634,Best_Val_AUC=0.7634\n",
      "(01:09:17)Epoch=3,BatchID=1600,Val_AUC=0.7633,Best_Val_AUC=0.7634\n",
      "(01:11:19)Epoch=3,BatchID=2000,Val_AUC=0.7632,Best_Val_AUC=0.7634\n",
      "(01:13:21)Epoch=3,BatchID=2400,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:15:24)Epoch=3,BatchID=2800,Val_AUC=0.7633,Best_Val_AUC=0.7635\n",
      "(01:17:27)Epoch=3,BatchID=3200,Val_AUC=0.7633,Best_Val_AUC=0.7635\n",
      "(01:19:24)Epoch=3,BatchID=3569,Val_AUC=0.7633,Best_Val_AUC=0.7635\n",
      "Reducing learning rate to 0.00001 @ T=14280!\n",
      "Updating regularizer @ T=14280!\n",
      "(01:20:58)Epoch=4,BatchID=0,Val_AUC=0.7633,Best_Val_AUC=0.7635\n",
      "(01:23:02)Epoch=4,BatchID=400,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:25:05)Epoch=4,BatchID=800,Val_AUC=0.7632,Best_Val_AUC=0.7635\n",
      "(01:27:07)Epoch=4,BatchID=1200,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:29:11)Epoch=4,BatchID=1600,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:31:13)Epoch=4,BatchID=2000,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:33:17)Epoch=4,BatchID=2400,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:35:20)Epoch=4,BatchID=2800,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:37:24)Epoch=4,BatchID=3200,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:39:21)Epoch=4,BatchID=3569,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "Reducing learning rate to 0.00000 @ T=17850!\n",
      "Updating regularizer @ T=17850!\n",
      "(01:40:54)Epoch=5,BatchID=0,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:42:58)Epoch=5,BatchID=400,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:45:01)Epoch=5,BatchID=800,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:47:04)Epoch=5,BatchID=1200,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:49:07)Epoch=5,BatchID=1600,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:51:10)Epoch=5,BatchID=2000,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:53:12)Epoch=5,BatchID=2400,Val_AUC=0.7634,Best_Val_AUC=0.7635\n",
      "(01:55:14)Epoch=5,BatchID=2800,Val_AUC=0.7633,Best_Val_AUC=0.7635\n",
      "(01:57:17)Epoch=5,BatchID=3200,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:59:16)Epoch=5,BatchID=3569,Val_AUC=0.7634,Best_Val_AUC=0.7635\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_after40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet34(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model_resnet34.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16143ddd-c407-447a-bfc9-81d21af806c1",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061944b7-034b-40b7-8bf9-0cd522ce6f31",
   "metadata": {},
   "source": [
    "## Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a9c90e-d0dc-4ac7-b63e-b86f5cc7b39a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 133781 images in total, 16297 positive images, 117484 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1218\n",
      "\n",
      "Found 133781 images in total, 42794 positive images, 90987 negative images\n",
      "Edema(C1): imbalance ratio is 0.3199\n",
      "\n",
      "Found 133781 images in total, 9055 positive images, 124726 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0677\n",
      "\n",
      "Found 133781 images in total, 41919 positive images, 91862 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3133\n",
      "\n",
      "Found 133781 images in total, 53675 positive images, 80106 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4012\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19090 images in total, 2242 positive images, 16848 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1174\n",
      "\n",
      "Found 19090 images in total, 6161 positive images, 12929 negative images\n",
      "Edema(C1): imbalance ratio is 0.3227\n",
      "\n",
      "Found 19090 images in total, 1346 positive images, 17744 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0705\n",
      "\n",
      "Found 19090 images in total, 5843 positive images, 13247 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3061\n",
      "\n",
      "Found 19090 images in total, 7762 positive images, 11328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4066\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:01:49)Epoch=0,BatchID=0,Val_AUC=0.5093,Best_Val_AUC=0.5093\n",
      "(00:04:34)Epoch=0,BatchID=400,Val_AUC=0.6835,Best_Val_AUC=0.6835\n",
      "(00:07:17)Epoch=0,BatchID=800,Val_AUC=0.7115,Best_Val_AUC=0.7115\n",
      "(00:10:01)Epoch=0,BatchID=1200,Val_AUC=0.7272,Best_Val_AUC=0.7272\n",
      "(00:12:43)Epoch=0,BatchID=1600,Val_AUC=0.7356,Best_Val_AUC=0.7356\n",
      "(00:15:25)Epoch=0,BatchID=2000,Val_AUC=0.7343,Best_Val_AUC=0.7356\n",
      "(00:18:08)Epoch=0,BatchID=2400,Val_AUC=0.7282,Best_Val_AUC=0.7356\n",
      "(00:20:53)Epoch=0,BatchID=2800,Val_AUC=0.7272,Best_Val_AUC=0.7356\n",
      "(00:23:37)Epoch=0,BatchID=3200,Val_AUC=0.7427,Best_Val_AUC=0.7427\n",
      "(00:26:20)Epoch=0,BatchID=3600,Val_AUC=0.7361,Best_Val_AUC=0.7427\n",
      "(00:29:03)Epoch=0,BatchID=4000,Val_AUC=0.7307,Best_Val_AUC=0.7427\n",
      "(00:30:55)Epoch=0,BatchID=4180,Val_AUC=0.7101,Best_Val_AUC=0.7427\n",
      "Reducing learning rate to 0.01000 @ T=4181!\n",
      "Updating regularizer @ T=4181!\n",
      "(00:32:35)Epoch=1,BatchID=0,Val_AUC=0.7135,Best_Val_AUC=0.7427\n",
      "(00:35:17)Epoch=1,BatchID=400,Val_AUC=0.7528,Best_Val_AUC=0.7528\n",
      "(00:37:59)Epoch=1,BatchID=800,Val_AUC=0.7555,Best_Val_AUC=0.7555\n",
      "(00:40:42)Epoch=1,BatchID=1200,Val_AUC=0.7568,Best_Val_AUC=0.7568\n",
      "(00:43:23)Epoch=1,BatchID=1600,Val_AUC=0.7588,Best_Val_AUC=0.7588\n",
      "(00:46:06)Epoch=1,BatchID=2000,Val_AUC=0.7551,Best_Val_AUC=0.7588\n",
      "(00:48:48)Epoch=1,BatchID=2400,Val_AUC=0.7578,Best_Val_AUC=0.7588\n",
      "(00:51:32)Epoch=1,BatchID=2800,Val_AUC=0.7581,Best_Val_AUC=0.7588\n",
      "(00:54:15)Epoch=1,BatchID=3200,Val_AUC=0.7580,Best_Val_AUC=0.7588\n",
      "(00:56:56)Epoch=1,BatchID=3600,Val_AUC=0.7562,Best_Val_AUC=0.7588\n",
      "(00:59:39)Epoch=1,BatchID=4000,Val_AUC=0.7601,Best_Val_AUC=0.7601\n",
      "(01:01:30)Epoch=1,BatchID=4180,Val_AUC=0.7590,Best_Val_AUC=0.7601\n",
      "Reducing learning rate to 0.00100 @ T=8362!\n",
      "Updating regularizer @ T=8362!\n",
      "(01:03:13)Epoch=2,BatchID=0,Val_AUC=0.7593,Best_Val_AUC=0.7601\n",
      "(01:05:56)Epoch=2,BatchID=400,Val_AUC=0.7626,Best_Val_AUC=0.7626\n",
      "(01:08:39)Epoch=2,BatchID=800,Val_AUC=0.7633,Best_Val_AUC=0.7633\n",
      "(01:11:21)Epoch=2,BatchID=1200,Val_AUC=0.7634,Best_Val_AUC=0.7634\n",
      "(01:14:04)Epoch=2,BatchID=1600,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:16:46)Epoch=2,BatchID=2000,Val_AUC=0.7635,Best_Val_AUC=0.7635\n",
      "(01:19:28)Epoch=2,BatchID=2400,Val_AUC=0.7639,Best_Val_AUC=0.7639\n",
      "(01:22:10)Epoch=2,BatchID=2800,Val_AUC=0.7634,Best_Val_AUC=0.7639\n",
      "(01:24:52)Epoch=2,BatchID=3200,Val_AUC=0.7636,Best_Val_AUC=0.7639\n",
      "(01:27:33)Epoch=2,BatchID=3600,Val_AUC=0.7638,Best_Val_AUC=0.7639\n",
      "(01:30:06)Epoch=2,BatchID=4000,Val_AUC=0.7642,Best_Val_AUC=0.7642\n",
      "(01:31:35)Epoch=2,BatchID=4180,Val_AUC=0.7641,Best_Val_AUC=0.7642\n",
      "Reducing learning rate to 0.00010 @ T=12543!\n",
      "Updating regularizer @ T=12543!\n",
      "(01:32:31)Epoch=3,BatchID=0,Val_AUC=0.7642,Best_Val_AUC=0.7642\n",
      "(01:34:51)Epoch=3,BatchID=400,Val_AUC=0.7642,Best_Val_AUC=0.7642\n",
      "(01:37:11)Epoch=3,BatchID=800,Val_AUC=0.7642,Best_Val_AUC=0.7642\n",
      "(01:39:32)Epoch=3,BatchID=1200,Val_AUC=0.7641,Best_Val_AUC=0.7642\n",
      "(01:41:52)Epoch=3,BatchID=1600,Val_AUC=0.7642,Best_Val_AUC=0.7642\n",
      "(01:44:11)Epoch=3,BatchID=2000,Val_AUC=0.7644,Best_Val_AUC=0.7644\n",
      "(01:46:29)Epoch=3,BatchID=2400,Val_AUC=0.7643,Best_Val_AUC=0.7644\n",
      "(01:48:48)Epoch=3,BatchID=2800,Val_AUC=0.7644,Best_Val_AUC=0.7644\n",
      "(01:51:07)Epoch=3,BatchID=3200,Val_AUC=0.7643,Best_Val_AUC=0.7644\n",
      "(01:53:27)Epoch=3,BatchID=3600,Val_AUC=0.7644,Best_Val_AUC=0.7644\n",
      "(01:55:46)Epoch=3,BatchID=4000,Val_AUC=0.7643,Best_Val_AUC=0.7644\n",
      "(01:57:15)Epoch=3,BatchID=4180,Val_AUC=0.7643,Best_Val_AUC=0.7644\n",
      "Reducing learning rate to 0.00001 @ T=16724!\n",
      "Updating regularizer @ T=16724!\n",
      "(01:58:12)Epoch=4,BatchID=0,Val_AUC=0.7644,Best_Val_AUC=0.7644\n",
      "(02:00:32)Epoch=4,BatchID=400,Val_AUC=0.7644,Best_Val_AUC=0.7644\n",
      "(02:02:51)Epoch=4,BatchID=800,Val_AUC=0.7643,Best_Val_AUC=0.7644\n",
      "(02:05:14)Epoch=4,BatchID=1200,Val_AUC=0.7645,Best_Val_AUC=0.7645\n",
      "(02:07:32)Epoch=4,BatchID=1600,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:09:50)Epoch=4,BatchID=2000,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:12:11)Epoch=4,BatchID=2400,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:14:30)Epoch=4,BatchID=2800,Val_AUC=0.7642,Best_Val_AUC=0.7645\n",
      "(02:16:48)Epoch=4,BatchID=3200,Val_AUC=0.7643,Best_Val_AUC=0.7645\n",
      "(02:19:07)Epoch=4,BatchID=3600,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:21:27)Epoch=4,BatchID=4000,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:22:56)Epoch=4,BatchID=4180,Val_AUC=0.7643,Best_Val_AUC=0.7645\n",
      "Reducing learning rate to 0.00000 @ T=20905!\n",
      "Updating regularizer @ T=20905!\n",
      "(02:23:53)Epoch=5,BatchID=0,Val_AUC=0.7643,Best_Val_AUC=0.7645\n",
      "(02:26:13)Epoch=5,BatchID=400,Val_AUC=0.7645,Best_Val_AUC=0.7645\n",
      "(02:28:32)Epoch=5,BatchID=800,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:30:51)Epoch=5,BatchID=1200,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:33:11)Epoch=5,BatchID=1600,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:35:31)Epoch=5,BatchID=2000,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:37:50)Epoch=5,BatchID=2400,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:40:10)Epoch=5,BatchID=2800,Val_AUC=0.7645,Best_Val_AUC=0.7645\n",
      "(02:42:29)Epoch=5,BatchID=3200,Val_AUC=0.7644,Best_Val_AUC=0.7645\n",
      "(02:44:48)Epoch=5,BatchID=3600,Val_AUC=0.7643,Best_Val_AUC=0.7645\n",
      "(02:47:06)Epoch=5,BatchID=4000,Val_AUC=0.7643,Best_Val_AUC=0.7645\n",
      "(02:48:35)Epoch=5,BatchID=4180,Val_AUC=0.7644,Best_Val_AUC=0.7645\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_origin\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED) \n",
    "model = Resnet50(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "                \n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','origin_model_resnet50.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ab4c4-2d6a-4bd7-b395-cc7790f72adb",
   "metadata": {},
   "source": [
    "## Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771a4d0f-e1a0-4977-963c-bcda0be3dfd6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 78644 images in total, 9943 positive images, 68701 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1264\n",
      "\n",
      "Found 78644 images in total, 24591 positive images, 54053 negative images\n",
      "Edema(C1): imbalance ratio is 0.3127\n",
      "\n",
      "Found 78644 images in total, 5314 positive images, 73330 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0676\n",
      "\n",
      "Found 78644 images in total, 24764 positive images, 53880 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3149\n",
      "\n",
      "Found 78644 images in total, 31305 positive images, 47339 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3981\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 11159 images in total, 1392 positive images, 9767 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1247\n",
      "\n",
      "Found 11159 images in total, 3541 positive images, 7618 negative images\n",
      "Edema(C1): imbalance ratio is 0.3173\n",
      "\n",
      "Found 11159 images in total, 762 positive images, 10397 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 11159 images in total, 3527 positive images, 7632 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3161\n",
      "\n",
      "Found 11159 images in total, 4573 positive images, 6586 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4098\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:00:41)Epoch=0,BatchID=0,Val_AUC=0.5070,Best_Val_AUC=0.5070\n",
      "(00:02:44)Epoch=0,BatchID=400,Val_AUC=0.7039,Best_Val_AUC=0.7039\n",
      "(00:04:46)Epoch=0,BatchID=800,Val_AUC=0.7303,Best_Val_AUC=0.7303\n",
      "(00:06:49)Epoch=0,BatchID=1200,Val_AUC=0.7228,Best_Val_AUC=0.7303\n",
      "(00:08:51)Epoch=0,BatchID=1600,Val_AUC=0.7376,Best_Val_AUC=0.7376\n",
      "(00:10:53)Epoch=0,BatchID=2000,Val_AUC=0.7245,Best_Val_AUC=0.7376\n",
      "(00:12:56)Epoch=0,BatchID=2400,Val_AUC=0.7325,Best_Val_AUC=0.7376\n",
      "(00:13:40)Epoch=0,BatchID=2457,Val_AUC=0.7273,Best_Val_AUC=0.7376\n",
      "Reducing learning rate to 0.01000 @ T=2458!\n",
      "Updating regularizer @ T=2458!\n",
      "(00:14:18)Epoch=1,BatchID=0,Val_AUC=0.7288,Best_Val_AUC=0.7376\n",
      "(00:16:19)Epoch=1,BatchID=400,Val_AUC=0.7545,Best_Val_AUC=0.7545\n",
      "(00:18:20)Epoch=1,BatchID=800,Val_AUC=0.7556,Best_Val_AUC=0.7556\n",
      "(00:20:22)Epoch=1,BatchID=1200,Val_AUC=0.7561,Best_Val_AUC=0.7561\n",
      "(00:22:23)Epoch=1,BatchID=1600,Val_AUC=0.7584,Best_Val_AUC=0.7584\n",
      "(00:24:25)Epoch=1,BatchID=2000,Val_AUC=0.7604,Best_Val_AUC=0.7604\n",
      "(00:26:26)Epoch=1,BatchID=2400,Val_AUC=0.7591,Best_Val_AUC=0.7604\n",
      "(00:27:10)Epoch=1,BatchID=2457,Val_AUC=0.7595,Best_Val_AUC=0.7604\n",
      "Reducing learning rate to 0.00100 @ T=4916!\n",
      "Updating regularizer @ T=4916!\n",
      "(00:27:47)Epoch=2,BatchID=0,Val_AUC=0.7595,Best_Val_AUC=0.7604\n",
      "(00:29:49)Epoch=2,BatchID=400,Val_AUC=0.7614,Best_Val_AUC=0.7614\n",
      "(00:31:50)Epoch=2,BatchID=800,Val_AUC=0.7617,Best_Val_AUC=0.7617\n",
      "(00:33:52)Epoch=2,BatchID=1200,Val_AUC=0.7620,Best_Val_AUC=0.7620\n",
      "(00:35:53)Epoch=2,BatchID=1600,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "(00:37:54)Epoch=2,BatchID=2000,Val_AUC=0.7620,Best_Val_AUC=0.7621\n",
      "(00:39:56)Epoch=2,BatchID=2400,Val_AUC=0.7620,Best_Val_AUC=0.7621\n",
      "(00:40:44)Epoch=2,BatchID=2457,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "Reducing learning rate to 0.00010 @ T=7374!\n",
      "Updating regularizer @ T=7374!\n",
      "(00:41:26)Epoch=3,BatchID=0,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "(00:43:28)Epoch=3,BatchID=400,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "(00:45:29)Epoch=3,BatchID=800,Val_AUC=0.7620,Best_Val_AUC=0.7621\n",
      "(00:47:31)Epoch=3,BatchID=1200,Val_AUC=0.7621,Best_Val_AUC=0.7621\n",
      "(00:49:32)Epoch=3,BatchID=1600,Val_AUC=0.7622,Best_Val_AUC=0.7622\n",
      "(00:51:34)Epoch=3,BatchID=2000,Val_AUC=0.7622,Best_Val_AUC=0.7622\n",
      "(00:53:35)Epoch=3,BatchID=2400,Val_AUC=0.7623,Best_Val_AUC=0.7623\n",
      "(00:54:18)Epoch=3,BatchID=2457,Val_AUC=0.7623,Best_Val_AUC=0.7623\n",
      "Reducing learning rate to 0.00001 @ T=9832!\n",
      "Updating regularizer @ T=9832!\n",
      "(00:54:56)Epoch=4,BatchID=0,Val_AUC=0.7623,Best_Val_AUC=0.7623\n",
      "(00:56:57)Epoch=4,BatchID=400,Val_AUC=0.7622,Best_Val_AUC=0.7623\n",
      "(00:58:59)Epoch=4,BatchID=800,Val_AUC=0.7622,Best_Val_AUC=0.7623\n",
      "(01:01:00)Epoch=4,BatchID=1200,Val_AUC=0.7623,Best_Val_AUC=0.7623\n",
      "(01:03:01)Epoch=4,BatchID=1600,Val_AUC=0.7624,Best_Val_AUC=0.7624\n",
      "(01:05:02)Epoch=4,BatchID=2000,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:07:04)Epoch=4,BatchID=2400,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:07:47)Epoch=4,BatchID=2457,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "Reducing learning rate to 0.00000 @ T=12290!\n",
      "Updating regularizer @ T=12290!\n",
      "(01:08:25)Epoch=5,BatchID=0,Val_AUC=0.7624,Best_Val_AUC=0.7624\n",
      "(01:10:27)Epoch=5,BatchID=400,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:12:28)Epoch=5,BatchID=800,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:14:29)Epoch=5,BatchID=1200,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:16:30)Epoch=5,BatchID=1600,Val_AUC=0.7622,Best_Val_AUC=0.7624\n",
      "(01:18:31)Epoch=5,BatchID=2000,Val_AUC=0.7623,Best_Val_AUC=0.7624\n",
      "(01:20:33)Epoch=5,BatchID=2400,Val_AUC=0.7622,Best_Val_AUC=0.7624\n",
      "(01:21:16)Epoch=5,BatchID=2457,Val_AUC=0.7623,Best_Val_AUC=0.7624\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_male\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet50(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','male_model_resnet50.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f89e4-45ed-4d46-86ab-acb9975fad53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154e6d7e-beee-42e0-bc46-2386c544dbe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 55137 images in total, 6354 positive images, 48783 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1152\n",
      "\n",
      "Found 55137 images in total, 18203 positive images, 36934 negative images\n",
      "Edema(C1): imbalance ratio is 0.3301\n",
      "\n",
      "Found 55137 images in total, 3741 positive images, 51396 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0678\n",
      "\n",
      "Found 55137 images in total, 17155 positive images, 37982 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3111\n",
      "\n",
      "Found 55137 images in total, 22370 positive images, 32767 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4057\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 7931 images in total, 850 positive images, 7081 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1072\n",
      "\n",
      "Found 7931 images in total, 2620 positive images, 5311 negative images\n",
      "Edema(C1): imbalance ratio is 0.3303\n",
      "\n",
      "Found 7931 images in total, 584 positive images, 7347 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0736\n",
      "\n",
      "Found 7931 images in total, 2316 positive images, 5615 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2920\n",
      "\n",
      "Found 7931 images in total, 3189 positive images, 4742 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4021\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:00:32)Epoch=0,BatchID=0,Val_AUC=0.5098,Best_Val_AUC=0.5098\n",
      "(00:02:28)Epoch=0,BatchID=400,Val_AUC=0.6983,Best_Val_AUC=0.6983\n",
      "(00:04:23)Epoch=0,BatchID=800,Val_AUC=0.7034,Best_Val_AUC=0.7034\n",
      "(00:06:18)Epoch=0,BatchID=1200,Val_AUC=0.7271,Best_Val_AUC=0.7271\n",
      "(00:08:13)Epoch=0,BatchID=1600,Val_AUC=0.7302,Best_Val_AUC=0.7302\n",
      "(00:09:05)Epoch=0,BatchID=1723,Val_AUC=0.7305,Best_Val_AUC=0.7305\n",
      "Reducing learning rate to 0.01000 @ T=1724!\n",
      "Updating regularizer @ T=1724!\n",
      "(00:09:35)Epoch=1,BatchID=0,Val_AUC=0.7309,Best_Val_AUC=0.7309\n",
      "(00:11:30)Epoch=1,BatchID=400,Val_AUC=0.7489,Best_Val_AUC=0.7489\n",
      "(00:13:25)Epoch=1,BatchID=800,Val_AUC=0.7511,Best_Val_AUC=0.7511\n",
      "(00:15:19)Epoch=1,BatchID=1200,Val_AUC=0.7543,Best_Val_AUC=0.7543\n",
      "(00:17:13)Epoch=1,BatchID=1600,Val_AUC=0.7547,Best_Val_AUC=0.7547\n",
      "(00:18:05)Epoch=1,BatchID=1723,Val_AUC=0.7539,Best_Val_AUC=0.7547\n",
      "Reducing learning rate to 0.00100 @ T=3448!\n",
      "Updating regularizer @ T=3448!\n",
      "(00:18:35)Epoch=2,BatchID=0,Val_AUC=0.7539,Best_Val_AUC=0.7547\n",
      "(00:20:29)Epoch=2,BatchID=400,Val_AUC=0.7557,Best_Val_AUC=0.7557\n",
      "(00:22:24)Epoch=2,BatchID=800,Val_AUC=0.7558,Best_Val_AUC=0.7558\n",
      "(00:24:18)Epoch=2,BatchID=1200,Val_AUC=0.7560,Best_Val_AUC=0.7560\n",
      "(00:26:13)Epoch=2,BatchID=1600,Val_AUC=0.7564,Best_Val_AUC=0.7564\n",
      "(00:27:04)Epoch=2,BatchID=1723,Val_AUC=0.7570,Best_Val_AUC=0.7570\n",
      "Reducing learning rate to 0.00010 @ T=5172!\n",
      "Updating regularizer @ T=5172!\n",
      "(00:27:34)Epoch=3,BatchID=0,Val_AUC=0.7569,Best_Val_AUC=0.7570\n",
      "(00:29:28)Epoch=3,BatchID=400,Val_AUC=0.7566,Best_Val_AUC=0.7570\n",
      "(00:31:22)Epoch=3,BatchID=800,Val_AUC=0.7564,Best_Val_AUC=0.7570\n",
      "(00:33:16)Epoch=3,BatchID=1200,Val_AUC=0.7562,Best_Val_AUC=0.7570\n",
      "(00:35:12)Epoch=3,BatchID=1600,Val_AUC=0.7566,Best_Val_AUC=0.7570\n",
      "(00:36:03)Epoch=3,BatchID=1723,Val_AUC=0.7553,Best_Val_AUC=0.7570\n",
      "Reducing learning rate to 0.00001 @ T=6896!\n",
      "Updating regularizer @ T=6896!\n",
      "(00:36:33)Epoch=4,BatchID=0,Val_AUC=0.7558,Best_Val_AUC=0.7570\n",
      "(00:38:28)Epoch=4,BatchID=400,Val_AUC=0.7568,Best_Val_AUC=0.7570\n",
      "(00:40:22)Epoch=4,BatchID=800,Val_AUC=0.7566,Best_Val_AUC=0.7570\n",
      "(00:42:16)Epoch=4,BatchID=1200,Val_AUC=0.7567,Best_Val_AUC=0.7570\n",
      "(00:44:10)Epoch=4,BatchID=1600,Val_AUC=0.7567,Best_Val_AUC=0.7570\n",
      "(00:45:01)Epoch=4,BatchID=1723,Val_AUC=0.7560,Best_Val_AUC=0.7570\n",
      "Reducing learning rate to 0.00000 @ T=8620!\n",
      "Updating regularizer @ T=8620!\n",
      "(00:45:31)Epoch=5,BatchID=0,Val_AUC=0.7562,Best_Val_AUC=0.7570\n",
      "(00:47:25)Epoch=5,BatchID=400,Val_AUC=0.7570,Best_Val_AUC=0.7570\n",
      "(00:49:19)Epoch=5,BatchID=800,Val_AUC=0.7566,Best_Val_AUC=0.7570\n",
      "(00:51:13)Epoch=5,BatchID=1200,Val_AUC=0.7566,Best_Val_AUC=0.7570\n",
      "(00:53:07)Epoch=5,BatchID=1600,Val_AUC=0.7567,Best_Val_AUC=0.7570\n",
      "(00:53:58)Epoch=5,BatchID=1723,Val_AUC=0.7568,Best_Val_AUC=0.7570\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_female\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet50(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','female_model_resnet50.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb959e8-2323-49ff-9ecf-c689aeaf06da",
   "metadata": {},
   "source": [
    "## before40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80679d48-6305-4c09-b6ad-5f72d023800b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 19562 images in total, 1817 positive images, 17745 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0929\n",
      "\n",
      "Found 19562 images in total, 4292 positive images, 15270 negative images\n",
      "Edema(C1): imbalance ratio is 0.2194\n",
      "\n",
      "Found 19562 images in total, 1250 positive images, 18312 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0639\n",
      "\n",
      "Found 19562 images in total, 4759 positive images, 14803 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2433\n",
      "\n",
      "Found 19562 images in total, 5784 positive images, 13778 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2957\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 2729 images in total, 228 positive images, 2501 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.0835\n",
      "\n",
      "Found 2729 images in total, 562 positive images, 2167 negative images\n",
      "Edema(C1): imbalance ratio is 0.2059\n",
      "\n",
      "Found 2729 images in total, 181 positive images, 2548 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0663\n",
      "\n",
      "Found 2729 images in total, 630 positive images, 2099 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.2309\n",
      "\n",
      "Found 2729 images in total, 755 positive images, 1974 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.2767\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:00:18)Epoch=0,BatchID=0,Val_AUC=0.5042,Best_Val_AUC=0.5042\n",
      "(00:02:02)Epoch=0,BatchID=400,Val_AUC=0.7223,Best_Val_AUC=0.7223\n",
      "(00:03:02)Epoch=0,BatchID=611,Val_AUC=0.7276,Best_Val_AUC=0.7276\n",
      "Reducing learning rate to 0.01000 @ T=612!\n",
      "Updating regularizer @ T=612!\n",
      "(00:03:21)Epoch=1,BatchID=0,Val_AUC=0.7296,Best_Val_AUC=0.7296\n",
      "(00:05:04)Epoch=1,BatchID=400,Val_AUC=0.7617,Best_Val_AUC=0.7617\n",
      "(00:06:04)Epoch=1,BatchID=611,Val_AUC=0.7616,Best_Val_AUC=0.7617\n",
      "Reducing learning rate to 0.00100 @ T=1224!\n",
      "Updating regularizer @ T=1224!\n",
      "(00:06:22)Epoch=2,BatchID=0,Val_AUC=0.7616,Best_Val_AUC=0.7617\n",
      "(00:08:05)Epoch=2,BatchID=400,Val_AUC=0.7649,Best_Val_AUC=0.7649\n",
      "(00:09:05)Epoch=2,BatchID=611,Val_AUC=0.7650,Best_Val_AUC=0.7650\n",
      "Reducing learning rate to 0.00010 @ T=1836!\n",
      "Updating regularizer @ T=1836!\n",
      "(00:09:23)Epoch=3,BatchID=0,Val_AUC=0.7651,Best_Val_AUC=0.7651\n",
      "(00:11:06)Epoch=3,BatchID=400,Val_AUC=0.7655,Best_Val_AUC=0.7655\n",
      "(00:12:06)Epoch=3,BatchID=611,Val_AUC=0.7655,Best_Val_AUC=0.7655\n",
      "Reducing learning rate to 0.00001 @ T=2448!\n",
      "Updating regularizer @ T=2448!\n",
      "(00:12:25)Epoch=4,BatchID=0,Val_AUC=0.7655,Best_Val_AUC=0.7655\n",
      "(00:14:07)Epoch=4,BatchID=400,Val_AUC=0.7655,Best_Val_AUC=0.7655\n",
      "(00:15:08)Epoch=4,BatchID=611,Val_AUC=0.7656,Best_Val_AUC=0.7656\n",
      "Reducing learning rate to 0.00000 @ T=3060!\n",
      "Updating regularizer @ T=3060!\n",
      "(00:15:26)Epoch=5,BatchID=0,Val_AUC=0.7656,Best_Val_AUC=0.7656\n",
      "(00:17:09)Epoch=5,BatchID=400,Val_AUC=0.7654,Best_Val_AUC=0.7656\n",
      "(00:18:08)Epoch=5,BatchID=611,Val_AUC=0.7653,Best_Val_AUC=0.7656\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_before40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet50(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','before40_model_resnet50.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da379c-68d1-48c9-89aa-09323e3e8e7e",
   "metadata": {},
   "source": [
    "## after40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8b320f2-1966-441e-8c8a-5cf5f7b3a32c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 114219 images in total, 14480 positive images, 99739 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1268\n",
      "\n",
      "Found 114219 images in total, 38502 positive images, 75717 negative images\n",
      "Edema(C1): imbalance ratio is 0.3371\n",
      "\n",
      "Found 114219 images in total, 7805 positive images, 106414 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0683\n",
      "\n",
      "Found 114219 images in total, 37160 positive images, 77059 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3253\n",
      "\n",
      "Found 114219 images in total, 47891 positive images, 66328 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4193\n",
      "\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 16361 images in total, 2014 positive images, 14347 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.1231\n",
      "\n",
      "Found 16361 images in total, 5599 positive images, 10762 negative images\n",
      "Edema(C1): imbalance ratio is 0.3422\n",
      "\n",
      "Found 16361 images in total, 1165 positive images, 15196 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.0712\n",
      "\n",
      "Found 16361 images in total, 5213 positive images, 11148 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3186\n",
      "\n",
      "Found 16361 images in total, 7007 positive images, 9354 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4283\n",
      "\n",
      "Start Training\n",
      "------------------------------\n",
      "(00:00:54)Epoch=0,BatchID=0,Val_AUC=0.5096,Best_Val_AUC=0.5096\n",
      "(00:03:08)Epoch=0,BatchID=400,Val_AUC=0.6956,Best_Val_AUC=0.6956\n",
      "(00:05:22)Epoch=0,BatchID=800,Val_AUC=0.7134,Best_Val_AUC=0.7134\n",
      "(00:07:36)Epoch=0,BatchID=1200,Val_AUC=0.7220,Best_Val_AUC=0.7220\n",
      "(00:09:49)Epoch=0,BatchID=1600,Val_AUC=0.7219,Best_Val_AUC=0.7220\n",
      "(00:12:04)Epoch=0,BatchID=2000,Val_AUC=0.7296,Best_Val_AUC=0.7296\n",
      "(00:14:18)Epoch=0,BatchID=2400,Val_AUC=0.7273,Best_Val_AUC=0.7296\n",
      "(00:16:32)Epoch=0,BatchID=2800,Val_AUC=0.7285,Best_Val_AUC=0.7296\n",
      "(00:18:46)Epoch=0,BatchID=3200,Val_AUC=0.7293,Best_Val_AUC=0.7296\n",
      "(00:20:54)Epoch=0,BatchID=3569,Val_AUC=0.7130,Best_Val_AUC=0.7296\n",
      "Reducing learning rate to 0.01000 @ T=3570!\n",
      "Updating regularizer @ T=3570!\n",
      "(00:21:44)Epoch=1,BatchID=0,Val_AUC=0.7158,Best_Val_AUC=0.7296\n",
      "(00:23:57)Epoch=1,BatchID=400,Val_AUC=0.7463,Best_Val_AUC=0.7463\n",
      "(00:26:11)Epoch=1,BatchID=800,Val_AUC=0.7495,Best_Val_AUC=0.7495\n",
      "(00:28:24)Epoch=1,BatchID=1200,Val_AUC=0.7507,Best_Val_AUC=0.7507\n",
      "(00:30:38)Epoch=1,BatchID=1600,Val_AUC=0.7490,Best_Val_AUC=0.7507\n",
      "(00:32:53)Epoch=1,BatchID=2000,Val_AUC=0.7509,Best_Val_AUC=0.7509\n",
      "(00:35:07)Epoch=1,BatchID=2400,Val_AUC=0.7511,Best_Val_AUC=0.7511\n",
      "(00:37:21)Epoch=1,BatchID=2800,Val_AUC=0.7514,Best_Val_AUC=0.7514\n",
      "(00:39:35)Epoch=1,BatchID=3200,Val_AUC=0.7542,Best_Val_AUC=0.7542\n",
      "(00:41:41)Epoch=1,BatchID=3569,Val_AUC=0.7510,Best_Val_AUC=0.7542\n",
      "Reducing learning rate to 0.00100 @ T=7140!\n",
      "Updating regularizer @ T=7140!\n",
      "(00:42:31)Epoch=2,BatchID=0,Val_AUC=0.7513,Best_Val_AUC=0.7542\n",
      "(00:44:44)Epoch=2,BatchID=400,Val_AUC=0.7557,Best_Val_AUC=0.7557\n",
      "(00:46:58)Epoch=2,BatchID=800,Val_AUC=0.7561,Best_Val_AUC=0.7561\n",
      "(00:49:11)Epoch=2,BatchID=1200,Val_AUC=0.7566,Best_Val_AUC=0.7566\n",
      "(00:51:25)Epoch=2,BatchID=1600,Val_AUC=0.7566,Best_Val_AUC=0.7566\n",
      "(00:53:39)Epoch=2,BatchID=2000,Val_AUC=0.7566,Best_Val_AUC=0.7566\n",
      "(00:55:53)Epoch=2,BatchID=2400,Val_AUC=0.7571,Best_Val_AUC=0.7571\n",
      "(00:58:07)Epoch=2,BatchID=2800,Val_AUC=0.7570,Best_Val_AUC=0.7571\n",
      "(01:00:21)Epoch=2,BatchID=3200,Val_AUC=0.7573,Best_Val_AUC=0.7573\n",
      "(01:02:27)Epoch=2,BatchID=3569,Val_AUC=0.7575,Best_Val_AUC=0.7575\n",
      "Reducing learning rate to 0.00010 @ T=10710!\n",
      "Updating regularizer @ T=10710!\n",
      "(01:03:17)Epoch=3,BatchID=0,Val_AUC=0.7575,Best_Val_AUC=0.7575\n",
      "(01:05:30)Epoch=3,BatchID=400,Val_AUC=0.7576,Best_Val_AUC=0.7576\n",
      "(01:07:44)Epoch=3,BatchID=800,Val_AUC=0.7576,Best_Val_AUC=0.7576\n",
      "(01:09:58)Epoch=3,BatchID=1200,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:12:12)Epoch=3,BatchID=1600,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:14:26)Epoch=3,BatchID=2000,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:16:40)Epoch=3,BatchID=2400,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:18:54)Epoch=3,BatchID=2800,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:21:08)Epoch=3,BatchID=3200,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:23:15)Epoch=3,BatchID=3569,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "Reducing learning rate to 0.00001 @ T=14280!\n",
      "Updating regularizer @ T=14280!\n",
      "(01:24:03)Epoch=4,BatchID=0,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:26:17)Epoch=4,BatchID=400,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:28:31)Epoch=4,BatchID=800,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:30:45)Epoch=4,BatchID=1200,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:32:59)Epoch=4,BatchID=1600,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:35:12)Epoch=4,BatchID=2000,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(01:37:26)Epoch=4,BatchID=2400,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:39:39)Epoch=4,BatchID=2800,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:41:54)Epoch=4,BatchID=3200,Val_AUC=0.7575,Best_Val_AUC=0.7577\n",
      "(01:44:01)Epoch=4,BatchID=3569,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "Reducing learning rate to 0.00000 @ T=17850!\n",
      "Updating regularizer @ T=17850!\n",
      "(01:44:50)Epoch=5,BatchID=0,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:47:04)Epoch=5,BatchID=400,Val_AUC=0.7575,Best_Val_AUC=0.7577\n",
      "(01:49:18)Epoch=5,BatchID=800,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(01:51:31)Epoch=5,BatchID=1200,Val_AUC=0.7575,Best_Val_AUC=0.7577\n",
      "(01:53:43)Epoch=5,BatchID=1600,Val_AUC=0.7575,Best_Val_AUC=0.7577\n",
      "(01:55:57)Epoch=5,BatchID=2000,Val_AUC=0.7574,Best_Val_AUC=0.7577\n",
      "(01:58:11)Epoch=5,BatchID=2400,Val_AUC=0.7577,Best_Val_AUC=0.7577\n",
      "(02:00:25)Epoch=5,BatchID=2800,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(02:02:39)Epoch=5,BatchID=3200,Val_AUC=0.7576,Best_Val_AUC=0.7577\n",
      "(02:04:45)Epoch=5,BatchID=3569,Val_AUC=0.7576,Best_Val_AUC=0.7577\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(os.getcwd(),'CheXpert_after40\\\\')\n",
    "# Index=-1 denotes multi-label with 5 diseases\n",
    "trainSet = CheXpert(csv_path=root+'train.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='train',class_index=-1,verbose=True)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',image_root_path=root,use_upsampling=False,use_frontal=True,image_size=224,mode='valid',class_index=-1,verbose=True)\n",
    "trainloader =  torch.utils.data.DataLoader(trainSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet,batch_size=BATCH_SIZE,num_workers=2,shuffle=False)\n",
    "\n",
    "# model\n",
    "set_all_seeds(SEED)\n",
    "model = Resnet50(pretrained=True,last_activation=None,activations='elu',num_classes=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "loss_fn = MultiLabelAUCMLoss(num_labels=5)\n",
    "optimizer = PESG(model.parameters(),\n",
    "                 loss_fn=loss_fn,\n",
    "                 lr=lr,\n",
    "                 margin=margin,\n",
    "                 epoch_decay=epoch_decay,\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "print ('Start Training')\n",
    "print ('-'*30)\n",
    "begin_time = datetime.now()\n",
    "\n",
    "best_val_auc = 0 \n",
    "for epoch in range(total_epochs):\n",
    "    if epoch > 0:\n",
    "        optimizer.update_regularizer(decay_factor=10)    \n",
    "\n",
    "    for idx,data in enumerate(trainloader):\n",
    "        train_data,train_labels = data\n",
    "        train_data,train_labels  = train_data.cuda(),train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        loss = loss_fn(y_pred,train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # validation  \n",
    "        if idx % 400 == 0 or idx == len(trainloader)-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx,data in enumerate(testloader):\n",
    "                    test_data,test_labels = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    y_pred = torch.sigmoid(y_pred)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_labels.numpy())\n",
    "            \n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                val_auc_mean = np.mean(auc_roc_score(test_true,test_pred)) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc_mean:\n",
    "                    best_val_auc = val_auc_mean\n",
    "                    # torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model.pth'))\n",
    "                    torch.save(model.state_dict(),os.path.join(os.getcwd(),'pth_files','after40_model_resnet50.pth'))\n",
    "                after_time = datetime.now()\n",
    "                time_gap = after_time-begin_time\n",
    "                time_gap = time_gap.total_seconds()\n",
    "                hours,remainders = divmod(time_gap,3600)\n",
    "                minutes,seconds = divmod(remainders,60)\n",
    "                hours = int(hours)\n",
    "                minutes = int(minutes)\n",
    "                seconds = int(seconds)\n",
    "                print(f'({hours:02d}:{minutes:02d}:{seconds:02d})Epoch={epoch},BatchID={idx},Val_AUC={val_auc_mean:.4f},Best_Val_AUC={best_val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d72f0-5e08-49f1-9370-88e443879385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
